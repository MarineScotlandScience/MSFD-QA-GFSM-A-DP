###################
# Version Control #
###################
# R version 3.2.2 (2015-08-14): Fire Safety 
# platform       x86_64-w64-mingw32 (64-bit)
###############
# Script Info #
###############
# This is Script 8 of 9 
# The purpose of this script is to seperate the surveys and 
# define the final data products structure for the haul files
# Then select the Standard Survey Area using the agreed criteria 
# AUTHOR: Meadhbh Moriarty, 2016
# REVIEWED BY:
#############
# Prep Data #
#############
# Here we assign the column names to the values that will appear in the top end 
# of the data product to insure transparency and it is user friendly
h<-hauls1
# check that the final list of hauls match in both groups
list<-unique(h$New_UniqueID)
list<-unique(dat8$New_UniqueID)
# fix time
summary(as.numeric(h$TimeShot))
h$TimeShot_numeric<-(as.numeric(h$TimeShot))
h$TimeShot_numeric[h$TimeShot_numeric>2359]<-h$TimeShot_numeric[h$TimeShot_numeric>2459]/100
find<-subset(h, TimeShot_numeric>2359,)
summary(as.numeric(h$TimeShot_numeric))
h$TimeShot<-h$TimeShot_numeric

#  Add Survey Acronyms from Data products
# See table 2.1 in Moriarty et al (in prep) for details 
names(h)
summary(h$Survey)
h$Survey_Acronym[h$Survey=="NS-IBTS"&h$Quarter=="1"]<-"GNSIntOT1"
h$Survey_Acronym[h$Survey=="NS-IBTS"&h$Quarter=="3"]<-"GNSIntOT3"
h$Survey_Acronym[h$Survey=="FR-CGFS"&h$Quarter=="4"]<-"GNSFraOT4"
h$Survey_Acronym[h$Survey=="SWC-IBTS"&h$Quarter=="1"]<-"CSScoOT1"
h$Survey_Acronym[h$Survey=="SWC-IBTS"&h$Quarter=="4"]<-"CSScoOT4"
h$Survey_Acronym[h$Survey=="IE-IGFS"&h$Quarter=="4"]<-"CSIreOT4"

h$Survey_Acronym[h$Survey=="NIGFS"&h$Quarter=="1"]<-"CSNIrOT1"
h$Survey_Acronym[h$Survey=="NIGFS"&h$Quarter=="4"]<-"CSNIrOT4"
h$Survey_Acronym[h$Survey=="EVHOE"&h$Quarter=="4"]<-"CSBBFraOT4"
h$Survey_Acronym[h$Survey=="SP_ARSA"&h$Quarter=="1"]<-"BBIC(s)SpaOT1"
h$Survey_Acronym[h$Survey=="SP_ARSA"&h$Quarter=="4"]<-"BBIC(s)SpaOT4"
h$Survey_Acronym[h$Survey=="SPNGFS"&h$Quarter=="4"]<-"BBIC(n)SpaOT4"

h$Survey_Acronym[h$Survey=="PT-IBTS"&h$Quarter=="4"]<-"BBICPorOT4"
h$Survey_Acronym[h$Survey=="ROCKALL"&h$Quarter=="3"]<-"WAScoOT3"
h$Survey_Acronym[h$Survey=="SP_PORC"&h$Quarter=="3"]<-"WASpaOT3"
h$Survey_Acronym[h$Survey=="BTS"&h$Quarter=="3"&
                   h$Country=="NED"]<-"GNSNetBT3"
h$Survey_Acronym[h$Survey=="BTS"&h$Quarter=="3"&
                   h$Country=="GFR"]<-"GNSGerBT3"
h$Survey_Acronym[h$Survey=="BTS"&h$Quarter=="3"&
                   h$Country=="ENG"]<-"GNSEngBT3"
h$Survey_Acronym[h$Survey=="BTS-VIIa"&h$Quarter=="3"&
                   h$Country=="ENG"]<-"CSEngBT3"
summary(as.factor(h$Survey_Acronym))
# add a gear type filer column
h$GearType[h$Survey=="BTS"|h$Survey=="BTS-VIIa"]<-"BT"
h$GearType[is.na(h$GearType)]<-"OT"
# new haul uniqu identifer Survey Acronym/ship/year/haul No
h$HaulID<-paste(h$Survey_Acronym,h$Ship,h$Year,h$HaulNo,sep="/")
h$YearShot<-h$Year                
h$MonthShot<-h$month                  
h$DayShot<-h$Day
#h$HourShot
#h$MinShot
names(hauls1)
summary(as.factor(hauls1$month))
h$HaulDur_min<-h$HaulDur
h$ICESStSq<-h$check_StatRec
h$SurvStratum<-h$Stratum
summary(as.factor(h$SurvStratum))
# Sort out strata 
names(h)
h$SurvStratum[h$Survey_Acronym=="GNSIntOT1"]<-h$ICESStSq[h$Survey_Acronym=="GNSIntOT1"]
h$SurvStratum[h$Survey_Acronym=="GNSIntOT3"]<-h$ICESStSq[h$Survey_Acronym=="GNSIntOT3"]
h$SurvStratum[h$Survey_Acronym=="GNSGerBT3"]<-h$ICESStSq[h$Survey_Acronym=="GNSGerBT3"]
h$SurvStratum[h$Survey_Acronym=="GNSNetBT3"]<-h$ICESStSq[h$Survey_Acronym=="GNSNetBT3"]
h$SurvStratum[h$Survey_Acronym=="GNSEngBT3"]<-h$ICESStSq[h$Survey_Acronym=="GNSEngBT3"]
find<-subset(h, is.na(SurvStratum),)
summary(as.factor(find$Survey_Acronym))
h$SurvStratum[is.na(h$SurvStratum)]<-"not_recorded"
# we don't believe the recorded wingspreads of 10 on the 
# CGFS - using modelled data instead. 
h$Use_WingSpread[h$Survey_Acronym=="GNSFraOT4"&h$Year=="2014"]<-h$mod1_wingspread_gov[h$Survey_Acronym=="GNSFraOT4"&h$Year=="2014"]
h$QualityWing[h$Survey_Acronym=="GNSFraOT4"&h$Year=="2014"]<-"mod1_wing_gov"
h$Depth_m<-h$DepthNew
h$Distance_km<-h$newDist/1000
h$WingSpread_m<-h$Use_WingSpread
h$DoorSpread_m<-h$Use_DoorSpread
h$NetOpen_m<-h$Use_Netopening
summary(h$SweptArea_wing_km_sqrd)
h$SweptArea_wing_m_sqrd<-h$Use_WingSpread*h$newDist
h$SweptArea_wing_km_sqrd<-h$SweptArea_wing_m_sqrd/1000/1000
h$WingSwpArea_sqkm<-h$SweptArea_wing_km_sqrd
h$WingSwpVol_CorF<-1/(h$Use_Netopening/1000)
h$DoorSwptArea_CorF<-(h$Use_WingSpread/1000)/(h$Use_DoorSpread/1000)
h$DoorSwptVol_CorF<-(h$Use_WingSpread/1000)/((h$Use_DoorSpread/1000)*(h$Use_Netopening/1000))
summary(h$WingSwpVol_CorF)
summary(h$DoorSwptArea_CorF)
summary(h$DoorSwptVol_CorF)
h$ShootLat_degdec<-h$ShootLat
h$ShootLong_degdec<-h$ShootLong
#check duplicate times in h file
h$date_time_check<-paste(h$Ship, h$Year, h$Quarter, h$month, h$Day, h$TimeShot, sep="/")
list<-(unique(h$date_time_check))
# 13 combos are the same
list<-h[duplicated(h$date_time_check),]
# this is a case of time not been updated on from the previous haul.
# an estimated time will be added into the dataset
haulID<-list$New_UniqueID
h$TimeShot[h$New_UniqueID=="IE-IGFS/2003/4/CEXP/73/GOV"&h$TimeShot=="1651"]<-1851
h$TimeShot[h$New_UniqueID=="IE-IGFS/2004/4/CEXP/11/GOV"&h$TimeShot=="813"]<-2013
h$TimeShot[h$New_UniqueID=="IE-IGFS/2004/4/CEXP/6/GOV"&h$TimeShot=="802"]<-1000
h$TimeShot[h$New_UniqueID=="IE-IGFS/2015/4/CEXP/102/GOV"&h$TimeShot=="745"]<-1400
h$TimeShot[h$New_UniqueID=="NS-IBTS/1995/1/WAH3/4/GOV"&h$TimeShot=="801"]<-2001
h$TimeShot[h$New_UniqueID=="NS-IBTS/1998/1/THA2/9/GOV"&h$TimeShot=="754"]<-1954
h$TimeShot[h$New_UniqueID=="NS-IBTS/2013/1/DAN2/37/GOV"&h$TimeShot=="632"]<-932
h$TimeShot[h$New_UniqueID=="NS-IBTS/2013/3/SCO3/243/GOV"&h$TimeShot=="1130"]<-1430
h$TimeShot[h$New_UniqueID=="NS-IBTS/2016/1/SCO3/38/GOV"&h$TimeShot=="1244"]<-1444
h$TimeShot[h$New_UniqueID=="ROCKALL/2015/3/SCO3/328/GOV"&h$TimeShot=="1054"]<-1300
h$TimeShot[h$New_UniqueID=="ROCKALL/2015/3/SCO3/346/GOV"&h$TimeShot=="926"]<-1130
h$TimeShot[h$New_UniqueID=="SWC-IBTS/2015/1/SCO3/62/GOV"&h$TimeShot=="1010"]<-1320
h$TimeShot[h$New_UniqueID=="SPNGFS/2006/4/CDS/78/BAK"&h$TimeShot=="614"]<-1814
h$TimeShot[h$New_UniqueID=="BTS/2003/3/ISI/11/BT8" &h$TimeShot=="925"]<-1125

h$TimeShot[h$New_UniqueID=="NS-IBTS/2016/3/SCO3/281/GOV" &h$TimeShot=="1424"]<-1705
find<-subset(h, h$Ship=="EZA", )
summary(as.factor(find$TimeShot))
#h$TimeShot[h$Ship=="EZA"]<-100*as.numeric(h$TimeShot[h$Ship=="EZA"])
# wash and repeat
h$date_time_check<-paste(h$Ship, h$Year, h$Quarter, h$month, h$Day, h$TimeShot, sep="/")
list<-(unique(h$date_time_check))
# 0 combos are the same
list<-h[duplicated(h$date_time_check),]
# thats one problem solved - now are the new haul id's unique?
list<-(unique(h$HaulID))
list<-h[duplicated(h$HaulID),]
# 2 corrections have been made to the decmil min - round to nearest min
h$HaulDur_min[h$New_UniqueID=="NS-IBTS/2008/3/JHJ/269/GOV"]<-23
h$HaulDur_min[h$New_UniqueID=="NS-IBTS/1999/3/MIC/619/GOV"]<-32
# no there are shed loads of duplicated ones - same problem as before I suspect with NI
# need to use station no not haul no.
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="17"]<-"CSNIrOT4/LF/1999/17"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="35"]<-"CSNIrOT4/LF/1999/35"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="46"]<-"CSNIrOT4/LF/1999/46"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="48"]<-"CSNIrOT4/LF/1999/48"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="50"]<-"CSNIrOT4/LF/1999/50"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="51"]<-"CSNIrOT4/LF/1999/51"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="56"]<-"CSNIrOT4/LF/1999/56"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="61"]<-"CSNIrOT4/LF/1999/61"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="63"]<-"CSNIrOT4/LF/1999/63"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="64"]<-"CSNIrOT4/LF/1999/64"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="70"]<-"CSNIrOT4/LF/1999/70"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="71"]<-"CSNIrOT4/LF/1999/71"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="73"]<-"CSNIrOT4/LF/1999/73"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="75"]<-"CSNIrOT4/LF/1999/75"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="76"]<-"CSNIrOT4/LF/1999/76"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="77"]<-"CSNIrOT4/LF/1999/77"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="79"]<-"CSNIrOT4/LF/1999/79"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="81"]<-"CSNIrOT4/LF/1999/81"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="83"]<-"CSNIrOT4/LF/1999/83"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="88"]<-"CSNIrOT4/LF/1999/88"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="90"]<-"CSNIrOT4/LF/1999/90"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="92"]<-"CSNIrOT4/LF/1999/92"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="93"]<-"CSNIrOT4/LF/1999/93"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="94"]<-"CSNIrOT4/LF/1999/94"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="96"]<-"CSNIrOT4/LF/1999/96"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="97"]<-"CSNIrOT4/LF/1999/97"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="99"]<-"CSNIrOT4/LF/1999/99"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="100"]<-"CSNIrOT4/LF/1999/100"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="101"]<-"CSNIrOT4/LF/1999/101"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="102"]<-"CSNIrOT4/LF/1999/102"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="103"]<-"CSNIrOT4/LF/1999/103"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="105"]<-"CSNIrOT4/LF/1999/105"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="208"]<-"CSNIrOT4/LF/1999/208"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="216"]<-"CSNIrOT4/LF/1999/216"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="242"]<-"CSNIrOT4/LF/1999/242"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="243"]<-"CSNIrOT4/LF/1999/243"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="245"]<-"CSNIrOT4/LF/1999/245"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="246"]<-"CSNIrOT4/LF/1999/246"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="249"]<-"CSNIrOT4/LF/1999/249"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="250"]<-"CSNIrOT4/LF/1999/250"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="256"]<-"CSNIrOT4/LF/1999/256"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="259"]<-"CSNIrOT4/LF/1999/259"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="94"]<-"CSNIrOT4/LF/1999/94"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="106"]<-"CSNIrOT4/LF/1999/106"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="93"]<-"CSNIrOT4/LF/1999/93"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="243"]<-"CSNIrOT4/LF/1999/243"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="17"]<-"CSNIrOT4/LF/1999/17"
h$HaulID[h$HaulID=="CSNIrOT4/LF/1999/1"&h$StNo=="250"]<-"CSNIrOT4/LF/1999/250"
h$HaulID[h$HaulID=="CSNIrOT1/LF/2002/9"&h$StNo=="243"]<-"CSNIrOT1/LF/2002/243"
h$HaulID[h$HaulID=="CSNIrOT1/LF/2002/15"&h$StNo=="250"]<-"CSNIrOT1/LF/2002/250"

# recheck
list<-(unique(h$HaulID))
list<-h[duplicated(h$HaulID),]
summary(h$WingSwpArea_sqkm)
summary(h$Depth_m)
summary(h$DoorSwptVol_CorF)


haul_dat<-subset(h, 
                 select=c(HaulID,Survey_Acronym,Ship,GearType,Gear, 
                          YearShot,MonthShot,DayShot,TimeShot, 
                          HaulDur_min,ShootLat_degdec,ShootLong_degdec,ICESStSq,
                          SurvStratum,Depth_m,Distance_km,WingSpread_m, 
                          DoorSpread_m, NetOpen_m,WingSwpArea_sqkm,
                          WingSwpVol_CorF, DoorSwptArea_CorF,DoorSwptVol_CorF))

for (cat in unique(haul_dat$Survey_Acronym)){
  mypath <- file.path(paste("Haul Diagnostics", cat, ".jpeg", sep = ""))
  jpeg(file=mypath)
  par(mfrow=c(2,3))
  d <- subset(haul_dat, Survey_Acronym == cat)
  plot(d$ShootLong_degdec, d$ShootLat_degdec, 
       main=unique(d$cat), pch=19, xlab="Longitude", 
       ylab="Latitude",cex=1.9)
  plot(europe, col="lightgrey", add=T)
  title(unique(d$cat))
  plot(d$HaulDur_min, d$Distance_km, pch=19, xlab="Time (min)", 
       ylab="Distance (km)", cex=1.9)
  x<-c(13:66)
  points(x, x*4*1.852/60, type="l", col="red", lwd=3)
  points(x, x*2*1.852/60, type="l", col="red", lty=2, lwd=2)
  points(x, x*6*1.852/60, type="l", col="red", lty=2, lwd=2)
  plot(d$Distance_km, d$WingSwpArea_sqkm, pch=19, xlab="Distance (km)", 
       ylab="Wing Spread (km2)", cex=1.9)
  plot(d$Depth_m, d$WingSpread_m, pch=19, xlab="Depth (m)", 
       ylab="Wing Spread (m)", cex=1.9)
  plot(d$Depth_m, d$DoorSpread_m, pch=19, xlab="Depth (m)", 
       ylab="Door Spread (m)", cex=1.9)
  plot(d$Depth_m, d$NetOpen_m, pch=19, xlab="Depth (m)", 
       ylab="Net Opening (m)", cex=1.9)
    dev.off()
}

write.csv(haul_dat, "Sampling_info_all_surveys_11-10-2016.csv")
write.csv(haul_dat, "Sampling_info_all_surveys1_11-10-2016.txt")
summary(as.factor(haul_dat$Survey_Acronym))
summary(as.factor(haul_dat$MonthShot))
BBICnSpaOT4<-subset(haul_dat, haul_dat$Survey_Acronym=="BBIC(n)SpaOT4",)
write.csv(BBICnSpaOT4, "Sampling_info_BBICnSpaOT4_11-10-2016.csv")

#"GNSIntOT1
GNSIntOT1<-subset(haul_dat, haul_dat$Survey_Acronym=="GNSIntOT1",)
write.csv(GNSIntOT1, "Sampling_info_GNSIntOT1_11-10-2016.csv")
#"GNSIntOT3"
GNSIntOT3<-subset(haul_dat, haul_dat$Survey_Acronym=="GNSIntOT3",)
write.csv(GNSIntOT3, "Sampling_info_GNSIntOT3_11-10-2016.csv")
#"GNSFraOT4"
GNSFraOT4<-subset(haul_dat, haul_dat$Survey_Acronym=="GNSFraOT4",)
write.csv(GNSFraOT4, "Sampling_info_GNSFraOT4_11-10-2016.csv")
#"CSScoOT1"
CSScoOT1<-subset(haul_dat, haul_dat$Survey_Acronym=="CSScoOT1",)
write.csv(CSScoOT1, "Sampling_info_CSScoOT1_11-10-2016.csv")
#"CSScoOT4"
CSScoOT4<-subset(haul_dat, haul_dat$Survey_Acronym=="CSScoOT4"&haul_dat$YearShot>1994,)
write.csv(CSScoOT4, "Sampling_info_CSScoOT4V1_11-10-2016.csv")
#"CSIreOT4"
CSIreOT4<-subset(haul_dat, haul_dat$Survey_Acronym=="CSIreOT4",)
write.csv(CSIreOT4, "Sampling_info_CSIreOT4_08-08-2016.csv")
plot(CSIreOT4$Depth_m, CSIreOT4$WingSpread_m)
#"CSNIrOT1"
CSNIrOT1<-subset(haul_dat, haul_dat$Survey_Acronym=="CSNIrOT1",)
write.csv(CSNIrOT1, "Sampling_info_CSNIrOT1_11-10-2016.csv")
#"CSNIrOT4"
CSNIrOT4<-subset(haul_dat, haul_dat$Survey_Acronym=="CSNIrOT4",)
write.csv(CSNIrOT4, "Sampling_info_CSNIrOT4_11-10-2016.csv")
#"CS/BBFraOT4"
CSBBFraOT4<-subset(haul_dat, haul_dat$Survey_Acronym=="CSBBFraOT4",)
write.csv(CSBBFraOT4, "Sampling_info_CSBBFraOT4_11-10-2016.csv")
#"BBIC(s)SpaOT1"
BBICsSpaOT1<-subset(haul_dat, haul_dat$Survey_Acronym=="BBIC(s)SpaOT1",)
write.csv(BBICsSpaOT1, "Sampling_info_BBIC(s)SpaOT1_11-10-2016.csv")
#"BBIC(s)SpaOT4"
BBICsSpaOT4<-subset(haul_dat, haul_dat$Survey_Acronym=="BBIC(s)SpaOT4",)
write.csv(BBICsSpaOT4, "Sampling_info_BBIC(s)SpaOT4_11-10-2016.csv")
#"BBIC(n)SpaOT4"
BBICnSpaOT4<-subset(haul_dat, haul_dat$Survey_Acronym=="BBIC(n)SpaOT4",)
write.csv(BBICnSpaOT4, "Sampling_info_BBIC(n)SpaOT4_11-10-2016.csv")
#"BBICPorOT4"
BBICPorOT4<-subset(haul_dat, haul_dat$Survey_Acronym=="BBICPorOT4",)
write.csv(BBICPorOT4, "Sampling_info_BBICPorOT4_11-10-2016.csv")
#"WAScoOT3"
WAScoOT3<-subset(haul_dat, haul_dat$Survey_Acronym=="WAScoOT3",)
write.csv(WAScoOT3, "Sampling_info_WAScoOT3_11-10-2016.csv")
#"WASpaOT3"
WASpaOT3<-subset(haul_dat, haul_dat$Survey_Acronym=="WASpaOT3",)
write.csv(WASpaOT3, "Sampling_info_WASpaOT3_11-10-2016.csv")
#"GNSNetBT3"
GNSNetBT3<-subset(haul_dat, haul_dat$Survey_Acronym=="GNSNetBT3"&haul_dat$YearShot>1998,)
write.csv(GNSNetBT3, "Sampling_info_GNSNetBT3V1_11-10-2016.csv")
#"GNSGerBT3"
GNSGerBT3<-subset(haul_dat, haul_dat$Survey_Acronym=="GNSGerBT3",)
write.csv(GNSGerBT3, "Sampling_info_GNSGerBT3_11-10-2016.csv")
#"GNSEngBT3"
GNSEngBT3<-subset(haul_dat, haul_dat$Survey_Acronym=="GNSEngBT3",)
write.csv(GNSEngBT3, "Sampling_info_GNSEngBT3_11-10-2016.csv")
#"CSEngBT3"
CSEngBT3<-subset(haul_dat, haul_dat$Survey_Acronym=="CSEngBT3",)
write.csv(CSEngBT3, "Sampling_info_CSEngBT3_11-10-2016.csv")
summary(as.factor(haul_dat$Survey_Acronym))
haul_dat1<-Reduce(rbind, 
                     list(WASpaOT3,BBICsSpaOT4,BBICsSpaOT1,
                          BBICnSpaOT4,WAScoOT3,BBICPorOT4,
                          CSBBFraOT4,CSNIrOT4,CSNIrOT1,
                          CSIreOT4,CSScoOT4,CSScoOT1,
                          CSEngBT3,GNSFraOT4,GNSIntOT3,
                          GNSIntOT1,GNSEngBT3,GNSNetBT3,
                          GNSGerBT3))
GNSint_remove<-c("GNSIntOT1/DAN2/1987/32")
haul_dat1<-subset(haul_dat1, !(haul_dat1$Survey_Acronym=="CSScoOT4"&haul_dat1$ShootLong_degdec< -13),)
44549-44544
haul_dat11<-subset(haul_dat1, !(haul_dat1$Survey_Acronym=="CSEngBT3"&haul_dat1$ShootLong_degdec>1),)
haul_dat1<-subset(haul_dat11, !HaulID%in%GNSint_remove,)
nrow(haul_dat1)
write.csv(haul_dat1, "SamplingInfo_AllSurveys_FullSMP_V2.csv")
#"GNSIntOT1"
GNSIntOT1<-subset(haul_dat1, haul_dat1$Survey_Acronym=="GNSIntOT1",)
GNSint_remove<-c("GNSIntOT1/DAN2/1987/32")
GNSIntOT1_1<-subset(GNSIntOT1, !HaulID%in%GNSint_remove,)
write.csv(GNSIntOT1, "SamplingInfo_GNSIntOT1_FullSMP_V2.csv")
#"GNSIntOT3"
GNSIntOT3<-subset(haul_dat1, haul_dat1$Survey_Acronym=="GNSIntOT3",)
write.csv(GNSIntOT3, "SamplingInfo_GNSIntOT3_FullSMP_V2.csv")
#"GNSFraOT4"
GNSFraOT4<-subset(haul_dat1, haul_dat1$Survey_Acronym=="GNSFraOT4",)
write.csv(GNSFraOT4, "SamplingInfo_GNSFraOT4_FullSMP_V2.csv")
#"CSScoOT1"
CSScoOT1<-subset(haul_dat1, haul_dat1$Survey_Acronym=="CSScoOT1",)
write.csv(CSScoOT1, "SamplingInfo_CSScoOT1_FullSMP_V2.csv")
#"CSScoOT4"
CSScoOT4<-subset(haul_dat1, haul_dat1$Survey_Acronym=="CSScoOT4"&haul_dat1$YearShot>1994,)
write.csv(CSScoOT4, "SamplingInfo_CSScoOT4V1_FullSMP_V2.csv")
#"CSIreOT4"
CSIreOT4<-subset(haul_dat1, haul_dat1$Survey_Acronym=="CSIreOT4",)
write.csv(CSIreOT4, "SamplingInfo_CSIreOT4_FullSMP_V2.csv")
plot(CSIreOT4$Depth_m, CSIreOT4$WingSpread_m)
#"CSNIrOT1"
CSNIrOT1<-subset(haul_dat1, haul_dat1$Survey_Acronym=="CSNIrOT1",)
write.csv(CSNIrOT1, "SamplingInfo_CSNIrOT1_FullSMP_V2.csv")
#"CSNIrOT4"
CSNIrOT4<-subset(haul_dat1, haul_dat1$Survey_Acronym=="CSNIrOT4",)
write.csv(CSNIrOT4, "SamplingInfo_CSNIrOT4_FullSMP_V2.csv")
#"CS/BBFraOT4"
CSBBFraOT4<-subset(haul_dat1, haul_dat1$Survey_Acronym=="CSBBFraOT4",)
write.csv(CSBBFraOT4, "SamplingInfo_CSBBFraOT4_FullSMP_V2.csv")
#"BBIC(s)SpaOT1"
BBICsSpaOT1<-subset(haul_dat1, haul_dat1$Survey_Acronym=="BBIC(s)SpaOT1",)
write.csv(BBICsSpaOT1, "SamplingInfo_BBIC(s)SpaOT1_FullSMP_V2.csv")
#"BBIC(s)SpaOT4"
BBICsSpaOT4<-subset(haul_dat1, haul_dat1$Survey_Acronym=="BBIC(s)SpaOT4",)
write.csv(BBICsSpaOT4, "SamplingInfo_BBIC(s)SpaOT4_FullSMP_V2.csv")
#"BBIC(n)SpaOT4"
BBICnSpaOT4<-subset(haul_dat1, haul_dat1$Survey_Acronym=="BBIC(n)SpaOT4",)
write.csv(BBICnSpaOT4, "SamplingInfo_BBIC(n)SpaOT4_FullSMP_V2.csv")
#"BBICPorOT4"
BBICPorOT4<-subset(haul_dat1, haul_dat1$Survey_Acronym=="BBICPorOT4",)
write.csv(BBICPorOT4, "SamplingInfo_BBICPorOT4_FullSMP_V2.csv")
#"WAScoOT3"
WAScoOT3<-subset(haul_dat1, haul_dat1$Survey_Acronym=="WAScoOT3", )
write.csv(WAScoOT3, "SamplingInfo_WAScoOT3_FullSMP_V2.csv")
#"WASpaOT3"#
WASpaOT3<-subset(haul_dat1, haul_dat1$Survey_Acronym=="WASpaOT3", )
write.csv(WASpaOT3, "SamplingInfo_WASpaOT3_FullSMP_V2.csv")
#"GNSNetBT3"
GNSNetBT3<-subset(haul_dat1, haul_dat1$Survey_Acronym=="GNSNetBT3"&haul_dat1$YearShot>1998,)
write.csv(GNSNetBT3, "SamplingInfo_GNSNetBT3V1_FullSMP_V2.csv")
#"GNSGerBT3"
GNSGerBT3<-subset(haul_dat1, haul_dat1$Survey_Acronym=="GNSGerBT3",)
write.csv(GNSGerBT3, "SamplingInfo_GNSGerBT3_FullSMP_V2.csv")
#"GNSEngBT3"
GNSEngBT3<-subset(haul_dat1, haul_dat1$Survey_Acronym=="GNSEngBT3",)
write.csv(GNSEngBT3, "SamplingInfo_GNSEngBT3_FullSMP_V2.csv")
#"CSEngBT3"
CSEngBT3<-subset(haul_dat1, haul_dat1$Survey_Acronym=="CSEngBT3",)
plot(CSEngBT3$ShootLong_degdec, CSEngBT3$ShootLat_degdec)
CSEngBT3<-subset(CSEngBT3, CSEngBT3$ShootLong_degdec<1,)
write.csv(CSEngBT3, "SamplingInfo_CSEngBT3_FullSMP_V2.csv")
######################################################
# Standardised Survey Area and Period Data Product. ##
######################################################
# Select standard survey areas
# Rule 1:Rectangle must be sampled in 50% of years
# Rule 2: the number of rectangles sampled at least once in 
# the years at the start and end of time series = 20% of total time series?

############## 1GNSGerBT3 ##############
# survey period 2002 -2015 break 2006 
# 13 years 
# Rule 1: 7 yrs or more

# Read file of HH data for "GNSGerBT3"
#GNSGerBT3<-read.csv("Sampling_info_GNSGerBT3_11-10-2016.csv")
# 664 samples
# 50% Rule 
names(GNSGerBT3)
Rect_summary<-ddply(GNSGerBT3, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(GNSGerBT3$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(GNSGerBT3, !ICESStSq%in%list_out,)
nrow(GNSGerBT3)-nrow(SSA_rule1)
# 32 samples removed in 6 ICESStSq
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
y<-round((x/100)*20)
max(as.numeric(GNSGerBT3$YearShot))-y
min(as.numeric(GNSGerBT3$YearShot))+y
# check min 2002-2004
min<-subset(Rect_summary2, YearShot>(as.numeric(min(GNSGerBT3$YearShot))+y))
list<-unique(min$ICESStSq)
# 20 in list - all retained
# check max 2013-2015
max<-subset(Rect_summary2, YearShot<(as.numeric(max(GNSGerBT3$YearShot))-y))
list<-unique(max$ICESStSq)
# 20 in list - all retained

# new file for SSA Sampling info
write.csv(SSA_rule1, "SamplingInfo_GNSGerBT3_SSASMP_V2.csv")
SSA_GNSGerBT3<-SSA_rule1
############### 2 GNSNetBT3 ###############
# Read file of HH data 
# survey period 1999 -2015 
#GNSNetBT3<-read.csv("Sampling_info_GNSNetBT3_11-10-2016.csv")
summary(GNSNetBT3$YearShot)
nrow(GNSNetBT3)
# remove all samples before 1999
step1<-subset(GNSNetBT3, YearShot>1998,)
summary(step1$YearShot)
nrow(GNSNetBT3)-nrow(step1)
# 2508 samples
# 50% Rule 
Rect_summary<-ddply(step1, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(step1$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(step1, !ICESStSq%in%list_out,)
nrow(step1)-nrow(SSA_rule1)
# 113 samples removed in 32 ICESStSq
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(step1$YearShot))-y
min(as.numeric(step1$YearShot))+y
# check max 2011-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(step1$YearShot))-y))
list<-unique(max$ICESStSq)
# 91 in list - all retained
# check min 1999-2003
min<-subset(Rect_summary2, YearShot<(min(as.numeric(step1$YearShot))+y))
list<-unique(min$ICESStSq)
# 89 in list -  2 rects not sampled
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)

# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_GNSNetBT3_SSASMP_V2.csv")
SSA_GNSNetBT3<-SSA_rule2
################ 3 GNSEngBT3 ################
# Read file of HH data 
# survey period 1990 -2015 
#GNSEngBT3<-read.csv("Sampling_info_GNSEngBT3_11-10-2016.csv")
# GNSEngBT3/END/2012/26 
# no fish data in the HL file - remove 
GNSEngBT3_1<-subset(GNSEngBT3, !HaulID=="GNSEngBT3/END/2012/26")
summary(GNSEngBT3_1$YearShot)
nrow(GNSEngBT3_1)
# 2386 samples
# 50% Rule 
Rect_summary<-ddply(GNSEngBT3_1, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(GNSEngBT3_1$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(GNSEngBT3_1, !ICESStSq%in%list_out,)
nrow(GNSEngBT3)-nrow(SSA_rule1)
# 127 hauls removed in 14 rectangles
# changes previous results now 139 samples out
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(GNSEngBT3$YearShot))-y
min(as.numeric(GNSEngBT3$YearShot))+y
# check max 2009-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(GNSEngBT3$YearShot))-y))
list<-unique(max$ICESStSq)
# 15 in list - all retained
# check min 1990-1996
min<-subset(Rect_summary2, YearShot<(min(as.numeric(GNSEngBT3$YearShot))+y))
list<-unique(min$ICESStSq)
# 15 in list -  all
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)

# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_GNSEngBT3_SSASMP_V2.csv")
SSA_GNSEngBT3<-SSA_rule2
##############4 GNSIntOT1##############
# Read file of HH data 
# survey period 1983 -2016 
#GNSIntOT1<-read.csv("Sampling_info_GNSIntOT1_11-10-2016.csv")
summary(GNSIntOT1$YearShot)
nrow(GNSIntOT1)
# Need to remove GNSIntOT1/DAN2/1987/32
GNSint_remove<-c("GNSIntOT1/DAN2/1987/32")
GNSIntOT1_1<-subset(GNSIntOT1, !HaulID%in%GNSint_remove,)

# 13516 samples
# 50% Rule 
Rect_summary<-ddply(GNSIntOT1_1, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(GNSIntOT1_1$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(GNSIntOT1_1, !ICESStSq%in%list_out,)
nrow(GNSIntOT1)-nrow(SSA_rule1)
# 254 hauls removed in 23 rectangles
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(GNSIntOT1_1$YearShot))-y
min(as.numeric(GNSIntOT1_1$YearShot))+y
# check max 2009-2016
max<-subset(Rect_summary2, YearShot>(max(as.numeric(GNSIntOT1_1$YearShot))-y))
list<-unique(max$ICESStSq)
# 172 in list - all retained
# check min 1983-1990
min<-subset(Rect_summary2, YearShot<(min(as.numeric(GNSIntOT1_1$YearShot))+y))
list<-unique(min$ICESStSq)
# 171 in list -  one needs to be removed
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
SSA_GNSIntOT1<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_GNSIntOT1_SSASMP_V2.csv")
############### 5 GNSIntOT3###############
# Read file of HH data 
# survey period 1998 -2015 
#GNSIntOT3<-read.csv("Sampling_info_GNSIntOT3_11-10-2016.csv")
summary(GNSIntOT3$YearShot)
nrow(GNSIntOT3)
# 5872 samples
# 50% Rule 
Rect_summary<-ddply(GNSIntOT3, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(GNSIntOT3$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(GNSIntOT3, !ICESStSq%in%list_out,)
nrow(GNSIntOT3)-nrow(SSA_rule1)
# 84 hauls removed in 14 rectangles
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(GNSIntOT3$YearShot))-y
min(as.numeric(GNSIntOT3$YearShot))+y
# check max 2011-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(GNSIntOT3$YearShot))-y))
list<-unique(max$ICESStSq)
# 168 in list - all retained
# check min 1998-2002
min<-subset(Rect_summary2, YearShot<(min(as.numeric(GNSIntOT3$YearShot))+y))
list<-unique(min$ICESStSq)
# 168 in list - all retained
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
SSA_GNSIntOT3<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_GNSIntOT3_SSASMP_V2.csv")
################6 GNSFraOT4 ################
# Read file of HH data 
# survey period 1988 -2014
#GNSFraOT4<-read.csv("Sampling_info_GNSFraOT4_11-10-2016.csv")
summary(GNSFraOT4$YearShot)
nrow(GNSFraOT4)
#  2398 samples
# 50% Rule 
Rect_summary<-ddply(GNSFraOT4, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(GNSFraOT4$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(GNSFraOT4, !ICESStSq%in%list_out,)
nrow(GNSFraOT4)-nrow(SSA_rule1)
# 0 hauls removed in 0 rectangles
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(GNSFraOT4$YearShot))-y
min(as.numeric(GNSFraOT4$YearShot))+y
# check max 2008-2014
max<-subset(Rect_summary2, YearShot>(max(as.numeric(GNSFraOT4$YearShot))-y))
list<-unique(max$ICESStSq)
# 16 in list - all retained
# check min 1988-1994
min<-subset(Rect_summary2, YearShot<(min(as.numeric(GNSFraOT4$YearShot))+y))
list<-unique(min$ICESStSq)
# 15 in list - 1 lost
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
SSA_GNSFraOT4<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_GNSFraOT4_SSASMP_V2.csv")
##############7 CSEngBT3###############
# Read file of HH data 
# survey period 1993 -2015
#CSEngBT3<-read.csv("Sampling_info_CSEngBT3_11-10-2016.csv")
# CSEngBT3/COR/2000/143 
# no fish data in the HL file - remove 
CSEngBT3_1<-subset(CSEngBT3, !HaulID=="CSEngBT3/COR/2000/143")
#CSENG_remove<-c("CSEngBT3/END/2014/122","CSEngBT3/END/2014/127",

summary(CSEngBT3_1$YearShot)

nrow(CSEngBT3_1)
summary(CSEngBT3$YearShot)
nrow(CSEngBT3)
#  2453 samples
# 50% Rule 
Rect_summary<-ddply(CSEngBT3_1, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(CSEngBT3_1$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(CSEngBT3_1, !ICESStSq%in%list_out,)
nrow(CSEngBT3_1)-nrow(SSA_rule1)
# 66 hauls removed in 10 rectangles
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(CSEngBT3_1$YearShot))-y
min(as.numeric(CSEngBT3_1$YearShot))+y
# check max 2010-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(CSEngBT3_1$YearShot))-y))
list<-unique(max$ICESStSq)
# 23 in list - all retained
# check min 1993-1998
min<-subset(Rect_summary2, YearShot<(min(as.numeric(CSEngBT3_1$YearShot))+y))
list<-unique(min$ICESStSq)
# 23 in list
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
SSA_CSEngBT3<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_CSEngBT3_SSASMP_V2.csv")
#############8 CSScoOT1#############
# Read file of HH data 
# survey period 1985 -2016
#CSScoOT1<-read.csv("Sampling_info_CSScoOT1_11-10-2016.csv")
summary(CSScoOT1$YearShot)
nrow(CSScoOT1)
#  1795 samples
# 50% Rule 
Rect_summary<-ddply(CSScoOT1, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(CSScoOT1$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(CSScoOT1, !ICESStSq%in%list_out,)
nrow(CSScoOT1)-nrow(SSA_rule1)
# 303 hauls removed in 30 rectangles
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(CSScoOT1$YearShot))-y
min(as.numeric(CSScoOT1$YearShot))+y
# check max 2009-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(CSScoOT1$YearShot))-y))
list<-unique(max$ICESStSq)
# 39 in list - all retained
# check min 1985-1992
min<-subset(Rect_summary2, YearShot<(min(as.numeric(CSScoOT1$YearShot))+y))
list<-unique(min$ICESStSq)
# 39 in list
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
SSA_CSScoOT1<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_CSScoOT1_SSASMP_V2.csv")
#############9 CSScoOT4 ############
# Read file of HH data 
# survey period 1990 -2015
#CSScoOT4<-read.csv("Sampling_info_CSScoOT4_11-10-2016.csv")
summary(CSScoOT4$YearShot)
nrow(CSScoOT4)
#  1525 samples
# remove all samples prior to 1995
step1<-subset(CSScoOT4, YearShot>1994,)
#1315 samples
# 50% Rule 
Rect_summary<-ddply(step1, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(step1$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(step1, !ICESStSq%in%list_out,)
nrow(step1)-nrow(SSA_rule1)
# 192 hauls removed
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(step1$YearShot))-y
min(as.numeric(step1$YearShot))+y
# check max 2011-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(step1$YearShot))-y))
list<-unique(max$ICESStSq)
# 43 in list - 7 lost
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
# redo Stat Rec Summary with new samples
Rect_summary2<-ddply(SSA_rule2, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# check min 1995-1999
min<-subset(Rect_summary2, YearShot<(min(as.numeric(step1$YearShot))+y))
list<-unique(min$ICESStSq)
# 42 in list
SSA_rule2_1<-subset(SSA_rule2, ICESStSq%in%list,)
SSA_CSScoOT4<-SSA_rule2_1
# new file for SSA Sampling info
write.csv(SSA_rule2_1, "SamplingInfo_CSScoOT4_SSASMP_V2.csv")
# Remove all intermediate files
##############10 CSIreOT4 #############
# Read file of HH data 
# survey period 2003 -2015
#CSIreOT4<-read.csv("Sampling_info_CSIreOT4_08-08-2016.csv")
summary(CSIreOT4$YearShot)
nrow(CSIreOT4)
#  2118 samples
# 50% Rule 
Rect_summary<-ddply(CSIreOT4, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(CSIreOT4$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(CSIreOT4, !ICESStSq%in%list_out,)
nrow(CSIreOT4)-nrow(SSA_rule1)
# 98 hauls removed
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(CSIreOT4$YearShot))-y
min(as.numeric(CSIreOT4$YearShot))+y
# check max 2012-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(CSIreOT4$YearShot))-y))
list<-unique(max$ICESStSq)
# 54 in list - all retained
# check min 2003-2006
min<-subset(Rect_summary2, YearShot<(min(as.numeric(CSIreOT4$YearShot))+y))
list<-unique(min$ICESStSq)
# 51 in list
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
SSA_CSIreOT4<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_CSIreOT4_SSASMP_V2.csv")
##############11 CSNIrOT1 ###############
# Read file of HH data 
# survey period 1992 -2015
#CSNIrOT1<-read.csv("Sampling_info_CSNIrOT1_11-10-2016.csv")
summary(CSNIrOT1$YearShot)
nrow(CSNIrOT1)
#  1172 samples
# 50% Rule 
Rect_summary<-ddply(CSNIrOT1, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(CSNIrOT1$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(CSNIrOT1, !ICESStSq%in%list_out,)
nrow(CSNIrOT1)-nrow(SSA_rule1)
# 96 hauls removed
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(CSNIrOT1$YearShot))-y
min(as.numeric(CSNIrOT1$YearShot))+y
# check max 2010-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(CSNIrOT1$YearShot))-y))
list<-unique(max$ICESStSq)
# 12 in list - all retained
# check min 1992-1997
min<-subset(Rect_summary2, YearShot<(min(as.numeric(CSNIrOT1$YearShot))+y))
list<-unique(min$ICESStSq)
# 12 in list
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
SSA_CSNIrOT1<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_CSNIrOT1_SSASMP_V2.csv")
##############12 CSNIrOT4 ##############
# Read file of HH data 
# survey period 1992 -2015
#CSNIrOT4<-read.csv("Sampling_info_CSNIrOT4_11-10-2016.csv")
summary(CSNIrOT4$YearShot)
nrow(CSNIrOT4)
#  1180 samples
# 50% Rule 
Rect_summary<-ddply(CSNIrOT4, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(CSNIrOT4$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(CSNIrOT4, !ICESStSq%in%list_out,)
nrow(CSNIrOT4)-nrow(SSA_rule1)
# 71 hauls removed
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(CSNIrOT4$YearShot))-y
min(as.numeric(CSNIrOT4$YearShot))+y
# check max 2010-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(CSNIrOT4$YearShot))-y))
list<-unique(max$ICESStSq)
# 13 in list - all retained
# check min 1992-1997
min<-subset(Rect_summary2, YearShot<(min(as.numeric(CSNIrOT4$YearShot))+y))
list<-unique(min$ICESStSq)
# 12 in list 1 lost
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)

SSA_CNNIrOT4<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_CSNIrOT4_SSASMP_V2.csv")
#################13CS/BBFraOT4 #################
# Read file of HH data 
# survey period 1997 -2015
#CSBBFraOT4<-read.csv("Sampling_info_CSBBFraOT4_11-10-2016.csv")
summary(CSBBFraOT4$YearShot)
nrow(CSBBFraOT4)
#  2641 samples
# 50% Rule 
Rect_summary<-ddply(CSBBFraOT4, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(CSBBFraOT4$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(CSBBFraOT4, !ICESStSq%in%list_out,)
nrow(CSBBFraOT4)-nrow(SSA_rule1)
# 52 hauls removed in 8 rect
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(CSBBFraOT4$YearShot))-y
min(as.numeric(CSBBFraOT4$YearShot))+y
# check max 2011-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(CSBBFraOT4$YearShot))-y))
list<-unique(max$ICESStSq)
# 65 in list - 1 lost
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
# check min 1997-2001
min<-subset(Rect_summary2, YearShot<(min(as.numeric(CSBBFraOT4$YearShot))+y))
list<-unique(min$ICESStSq)
# 12 in list 1 lost
SSA_rule2<-subset(SSA_rule2, ICESStSq%in%list,)
SSA_CSBBFraOT4<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_CSBBFraOT4_SSASMP_V2.csv")
##################14 BBICPorOT4 ###################
# Read file of HH data 
# survey period 2002 -2014
#BBICPorOT4<-read.csv("Sampling_info_BBICPorOT4_11-10-2016.csv")
summary(BBICPorOT4$YearShot)
nrow(BBICPorOT4)
#  866 samples
# 50% Rule 
Rect_summary<-ddply(BBICPorOT4, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(BBICPorOT4$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(BBICPorOT4, !ICESStSq%in%list_out,)
nrow(BBICPorOT4)-nrow(SSA_rule1)
# 9 hauls removed in 2 rect
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(BBICPorOT4$YearShot))-y
min(as.numeric(BBICPorOT4$YearShot))+y
# check max 2012-2014
max<-subset(Rect_summary2, YearShot>(max(as.numeric(BBICPorOT4$YearShot))-y))
list<-unique(max$ICESStSq)
# 20 in list - allretained
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
# check min 2002-2004
min<-subset(Rect_summary2, YearShot<(min(as.numeric(BBICPorOT4$YearShot))+y))
list<-unique(min$ICESStSq)
# 18 in list 2 lost
SSA_rule2<-subset(SSA_rule2, ICESStSq%in%list,)
SSA_BBICPorOT4<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_BBICPorOT4_SSASMP_V2.txt")
write.csv(SSA_BBICPorOT4, "SamplingInfo_BBICPorOT4_SSASMP_V2.csv")
##############15 WAScoOT3##############
# Read file of HH data 
# survey period 1999 -2015
#WAScoOT3<-read.csv("Sampling_info_WAScoOT3_11-10-2016.csv")
summary(WAScoOT3$YearShot)
nrow(WAScoOT3)
#  565 samples
# 50% Rule 
Rect_summary<-ddply(WAScoOT3, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(WAScoOT3$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(WAScoOT3, !ICESStSq%in%list_out,)
nrow(WAScoOT3)-nrow(SSA_rule1)
# 21 hauls removed in 5 rect
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(WAScoOT3$YearShot))-y
min(as.numeric(WAScoOT3$YearShot))+y
# check max 2012-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(WAScoOT3$YearShot))-y))
list<-unique(max$ICESStSq)
# 8 in list - allretained
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
# check min 1999-2002
min<-subset(Rect_summary2, YearShot<(min(as.numeric(WAScoOT3$YearShot))+y))
list<-unique(min$ICESStSq)
# 18 in list 2 lost
SSA_rule2<-subset(SSA_rule2, ICESStSq%in%list,)
SSA_WAScoOT3<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_WAScoOT3_SSASMP_V2.csv")
####################16 BBIC(n)SpaOT4 ####################
#BBICnSpaOT4<-read.csv("Sampling_info_BBICnSpaOT4_11-10-2016.csv")
summary(BBICnSpaOT4$YearShot)
nrow(BBICnSpaOT4)
#  565 samples
# 50% Rule 
Rect_summary<-ddply(BBICnSpaOT4, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(BBICnSpaOT4$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(BBICnSpaOT4, !ICESStSq%in%list_out,)
nrow(BBICnSpaOT4)-nrow(SSA_rule1)
# 77 hauls removed in 4 rect
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(BBICnSpaOT4$YearShot))-y
min(as.numeric(BBICnSpaOT4$YearShot))+y
# check max 2012-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(BBICnSpaOT4$YearShot))-y))
list<-unique(max$ICESStSq)
# 7 in list
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
# check min 1999-2002
min<-subset(Rect_summary2, YearShot<(min(as.numeric(BBICnSpaOT4$YearShot))+y))
list<-unique(min$ICESStSq)
# 7 in list
SSA_rule2<-subset(SSA_rule2, ICESStSq%in%list,)
SSA_BBICnSpaOT4<-SSA_rule2

# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_BBICnSpaOT4_SSASMP_V2.csv")
####################17 BBIC(s)SpaOT1 ####################
#BBICsSpaOT1<-read.csv("Sampling_info_BBIC(s)SpaOT1_11-10-2016.csv")
summary(BBICsSpaOT1$YearShot)
nrow(BBICsSpaOT1)
#  565 samples
# 50% Rule 
Rect_summary<-ddply(BBICsSpaOT1, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(BBICsSpaOT1$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(BBICsSpaOT1, !ICESStSq%in%list_out,)
nrow(BBICsSpaOT1)-nrow(SSA_rule1)
# 8 hauls removed in 1 rect
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(BBICsSpaOT1$YearShot))-y
min(as.numeric(BBICsSpaOT1$YearShot))+y
# check max 2012-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(BBICsSpaOT1$YearShot))-y))
list<-unique(max$ICESStSq)
# 5 in list - allretained
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
# check min 1999-2002
min<-subset(Rect_summary2, YearShot<(min(as.numeric(BBICsSpaOT1$YearShot))+y))
list<-unique(min$ICESStSq)
# 5 in list 
SSA_rule2<-subset(SSA_rule2, ICESStSq%in%list,)
SSA_BBICsSpaOT1<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_BBICsSpaOT1_SSASMP_V2.csv")
####################18 BBIC(s)SpaOT4 ####################
#BBICsSpaOT4<-read.csv("Sampling_info_BBIC(s)SpaOT4_11-10-2016.csv")
summary(BBICsSpaOT4$YearShot)
nrow(BBICsSpaOT4)
#  565 samples
# 50% Rule 
Rect_summary<-ddply(BBICsSpaOT4, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(BBICsSpaOT4$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(BBICsSpaOT4, !ICESStSq%in%list_out,)
nrow(BBICsSpaOT4)-nrow(SSA_rule1)
# 4 hauls removed in 1 rect
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(BBICsSpaOT4$YearShot))-y
min(as.numeric(BBICsSpaOT4$YearShot))+y
# check max 2012-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(BBICsSpaOT4$YearShot))-y))
list<-unique(max$ICESStSq)
# 5 in list 
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
# check min
min<-subset(Rect_summary2, YearShot<(min(as.numeric(BBICsSpaOT4$YearShot))+y))
list<-unique(min$ICESStSq)
# 5 in list 
SSA_rule2<-subset(SSA_rule2, ICESStSq%in%list,)
SSA_BBICsSpaOT4<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_BBICsSpaOT4_SSASMP_V2.csv")
###############19 WASpaOT3 ###############
#WASpaOT3<-read.csv("Sampling_info_WASpaOT3_11-10-2016.csv")
summary(WASpaOT3$YearShot)
nrow(WASpaOT3)
#  565 samples
# 50% Rule 
Rect_summary<-ddply(WASpaOT3, c("ICESStSq"), summarise,
                    N=length(unique(YearShot)))
x<-length(unique(WASpaOT3$YearShot))
x/2
out<-subset(Rect_summary, N<(ceiling(x/2)))
list_out<-out$ICESStSq
SSA_rule1<-subset(WASpaOT3, !ICESStSq%in%list_out,)
nrow(WASpaOT3)-nrow(SSA_rule1)
# 21hauls removed in 1 rect
# Rule 2 Rectangle must be sampled within first and last 20% of years
Rect_summary2<-ddply(SSA_rule1, c("ICESStSq", "YearShot"), summarise,
                     N=length(unique(HaulID)))
# round up to higher whole number
y<-ceiling((x/100)*20)
max(as.numeric(WASpaOT3$YearShot))-y
min(as.numeric(WASpaOT3$YearShot))+y
# check max 2012-2015
max<-subset(Rect_summary2, YearShot>(max(as.numeric(WASpaOT3$YearShot))-y))
list<-unique(max$ICESStSq)
# 17 in list 
SSA_rule2<-subset(SSA_rule1, ICESStSq%in%list,)
# check min 1999-2002
min<-subset(Rect_summary2, YearShot<(min(as.numeric(WASpaOT3$YearShot))+y))
list<-unique(min$ICESStSq)
# 17 in list 
SSA_rule2<-subset(SSA_rule2, ICESStSq%in%list,)
SSA_WASpaOT3<-SSA_rule2
# new file for SSA Sampling info
write.csv(SSA_rule2, "SamplingInfo_WASpaOT3_SSASMP_V2.csv")
#########################
# Diagnostics Haul Data #
#########################
SSA_haul_dat<-Reduce(rbind, 
                     list(SSA_WASpaOT3,SSA_BBICsSpaOT4,SSA_BBICsSpaOT1,
                          SSA_BBICnSpaOT4,SSA_WAScoOT3,SSA_BBICPorOT4,
                          SSA_CSBBFraOT4,SSA_CNNIrOT4,SSA_CSNIrOT1,
                          SSA_CSIreOT4,SSA_CSScoOT4,SSA_CSScoOT1,
                          SSA_CSEngBT3,SSA_GNSFraOT4,SSA_GNSIntOT3,
                          SSA_GNSIntOT1,SSA_GNSEngBT3,SSA_GNSNetBT3,
                          SSA_GNSGerBT3))
nrow(SSA_haul_dat)
nrow(SSA_WASpaOT3)+  nrow(SSA_BBICsSpaOT4)+ nrow(SSA_BBICsSpaOT1)+nrow(SSA_BBICnSpaOT4)+
  nrow(SSA_WAScoOT3) +nrow(SSA_BBICPorOT4)+  nrow(SSA_CSBBFraOT4)+nrow(SSA_CNNIrOT4)+
  nrow(SSA_CSNIrOT1)+nrow(SSA_CSIreOT4)+nrow(SSA_CSScoOT4)+nrow(SSA_CSScoOT1)+
  nrow(SSA_CSEngBT3)+nrow(SSA_GNSFraOT4)+nrow(SSA_GNSIntOT3)+nrow(SSA_GNSIntOT1)+
  nrow(SSA_GNSEngBT3)+nrow(SSA_GNSNetBT3)+nrow(SSA_GNSGerBT3)

summary(as.factor(SSA_haul_dat$Survey_Acronym))
for (cat in unique(SSA_haul_dat$Survey_Acronym)){
  mypath <- file.path(paste("SSA Haul Diagnostics", cat, ".jpeg", sep = ""))
  jpeg(file=mypath)
  par(mfrow=c(2,3),oma = c(0, 0, 2, 0))
  d <- subset(SSA_haul_dat, Survey_Acronym == cat)
  plot(d$ShootLong_degdec, d$ShootLat_degdec, 
       title=unique(d$cat), pch=19, xlab="Longitude", 
       ylab="Latitude",cex.lab=1.5)
  plot(europe, col="lightgrey", add=T)
  mtext(cat, outer = TRUE, cex = 1.5)
  plot(d$HaulDur_min, d$Distance_km, pch=19, xlab="Time (min)", 
       ylab="Distance (km)", cex.lab=1.5)
  x<-c(13:66)
  points(x, x*4*1.852/60, type="l", col="red", lwd=3)
  points(x, x*2*1.852/60, type="l", col="red", lty=2, lwd=2)
  points(x, x*6*1.852/60, type="l", col="red", lty=2, lwd=2)
  plot(d$Distance_km, d$WingSwpArea_sqkm, pch=19, xlab="Distance (km)", 
       ylab="Wing Spread (km2)", cex.lab=1.5)
  plot(d$Depth_m, d$WingSpread_m, pch=19, xlab="Depth (m)", 
       ylab="Wing Spread (m)", cex.lab=1.5)
  plot(d$Depth_m, d$DoorSpread_m, pch=19, xlab="Depth (m)", 
       ylab="Door Spread (m)", cex.lab=1.5)
  plot(d$Depth_m, d$NetOpen_m, pch=19, xlab="Depth (m)", 
       ylab="Net Opening (m)", cex.lab=1.5)
  dev.off()
}
summary(as.factor(haul_dat1$Survey_Acronym))

for (cat in unique(haul_dat1$Survey_Acronym)){
  mypath <- file.path(paste("Full Haul Diagnostics", cat, ".jpeg", sep = ""))
  jpeg(file=mypath)
  par(mfrow=c(2,3),oma = c(0, 0, 2, 0))
  d <- subset(haul_dat1, Survey_Acronym == cat)
  plot(d$ShootLong_degdec, d$ShootLat_degdec, 
       main=unique(d$cat), pch=19, xlab="Longitude", 
       ylab="Latitude",cex.lab=1.5)
  plot(europe, col="lightgrey", add=T)
  mtext(cat, outer = TRUE, cex = 1.5)
  plot(d$HaulDur_min, d$Distance_km, pch=19, xlab="Time (min)", 
       ylab="Distance (km)", cex.lab=1.5)
  x<-c(13:66)
  points(x, x*4*1.852/60, type="l", col="red", lwd=3)
  points(x, x*2*1.852/60, type="l", col="red", lty=2, lwd=2)
  points(x, x*6*1.852/60, type="l", col="red", lty=2, lwd=2)
  plot(d$Distance_km, d$WingSwpArea_sqkm, pch=19, xlab="Distance (km)", 
       ylab="Wing Spread (km2)", cex.lab=1.5)
  plot(d$Depth_m, d$WingSpread_m, pch=19, xlab="Depth (m)", 
       ylab="Wing Spread (m)", cex.lab=1.5)
  plot(d$Depth_m, d$DoorSpread_m, pch=19, xlab="Depth (m)", 
       ylab="Door Spread (m)", cex.lab=1.5)
  plot(d$Depth_m, d$NetOpen_m, pch=19, xlab="Depth (m)", 
       ylab="Net Opening (m)", cex.lab=1.5)
  dev.off()
}

write.csv(SSA_haul_dat, "SamplingInfo_AllSurveys_SSASMP_V2.csv")
SSA_haul_dat<-read.csv("SamplingInfo_AllSurveys_SSASMP_V2.csv")
