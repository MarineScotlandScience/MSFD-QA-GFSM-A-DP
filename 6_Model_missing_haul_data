###################
# Version Control #
###################
# R version 3.2.2 (2015-08-14): Fire Safety 
# platform       x86_64-w64-mingw32 (64-bit)
###############
# Script Info #
###############
# This is Script 6 of 9 
# The next step is to model missing data in the haul data of the surveys, and plot 
# lots of graphs to check all the haul stuff is believable now!
# AUTHOR: Meadhbh Moriarty, 2016
# REVIEWED BY: 

########################
# Check all -9 are ~NA #
########################
# All -9 should be NA as -9 represents a missing value in DATRAS
# Funtion to replace multiple -9 across lots of data tables
system.time(replace_function(hauls))
names(hauls)
# resturcture data table correctly
numCols <- c("Quarter", "SweepLngt", "HaulNo", "Year", "month",
             "Day", "TimeShot", "HaulDur", "ShootLat", "ShootLong", "HaulLat",
             "HaulLong", "Depth", "Netopening",  "Distance", "Warplngt", 
            "DoorSpread", "WingSpread", "GroundSpeed" , "SpeedWater")
hauls[, (numCols) := lapply(.SD, as.numeric), .SDcols = numCols]
####################
# Station Location #
####################
summary(as.factor(hauls$Stratum))
# 37283 NA's
summary(as.factor(hauls$StatRec))
# 113 NA's
ices<-read.csv("./Regional Boundaries Maps and Data/ICES_rectangles_statistics/Ices_rect_table.csv")
names(ices)
# shoot longs that are NA should be -9 , silly DATRAS -9 thing messing stuff up here!
long_error<-hauls[is.na(hauls$ShootLong)]
list<-long_error$UniqueID
hauls$ShootLong[hauls$UniqueID%in%list]<--9
# check haul positions match ICES Stats
names(hauls)
lat<-hauls$ShootLat
hauls$check_StatRec<- ices.rect2(hauls$ShootLong, hauls$ShootLat)
summary(as.factor(hauls$check_StatRec))
summary(as.factor(hauls$Survey))
check<-subset(hauls, !(hauls$check_StatRec%in%hauls$StatRec))
check<-subset(hauls, is.na(hauls$Stratum),)
summary(as.factor(check$Survey))
# use Check StatRec col = mistakes in actual Stat Rec.

# need to assign stratum based on survey!

# need maps
###############################
####Estimate Missing Depth#####
###############################

hauls$EstDepth<-hauls$Depth

# 767 observations
# All observations with no depth have no haul positional data 
# estimate depth on shoot position is the best we can do
library(marmap)
summary(hauls$ShootLat)
summary(as.numeric(hauls$ShootLong))

# use NOAA website to get bathy map
papoue <- getNOAA.bathy(lon1 = -16, lon2 = 13,
                        lat1 = 62, lat2 = 36, resolution = .5)
summary(papoue)
# make a pretty map of all the stations
png(file = "surveydepthmap.png", bg = "transparent")
blues <- c("lightsteelblue4", "lightsteelblue3",
           "lightsteelblue2", "lightsteelblue1")
greys <- c(grey(0.99), grey(0.95), grey(0.85))
plot(papoue, image = TRUE, land = FALSE, lwd = 0.03,
     bpal = list(c(0, max(papoue), greys),
                 c(min(papoue), 0, blues)))
plot(papoue, n = 1, lwd = 0.04, add = TRUE)
cols<-heat_hcl(13, c = c(80, 30), l=c(30,90), power=c(1/5, 1.5))
hauls$Survey<-(as.factor(hauls$Survey))
points(hauls$ShootLong, hauls$ShootLat, pch=19, 
       cex=0.3, col=cols[hauls$Survey])
dev.off()
# get 
hauls$ShootLong<-as.numeric(hauls$ShootLong)
NOAA_Depth<-get.depth(papoue, x=hauls$ShootLong, y=hauls$ShootLat, locator=FALSE)

hauls$EstDepth<-(NOAA_Depth$depth*-1)
hauls$DepthNew<-hauls$Depth
hauls$DepthNew[is.na(hauls$Depth)]<-hauls$EstDepth[is.na(hauls$Depth)] 
summary(hauls$DepthNew)
# make a graph of all the difference between estimated and recorded depths
png(file = "depth_differences.png", bg = "transparent")
plot(hauls$Depth, hauls$EstDepth, pch=19, xlab="Recorded Depth (m)",
     ylab="Estimated point depth (m)")
abline(a=0, b=1, col="red")
dev.off()
write.csv(papoue, "Bathy_map_26-05-2016.csv")
################
# Sweep Length #
################
summary(as.factor(hauls$SweepLngt))
# Sweep Lenght Values are sometimes incorrect or missing, 
# delete incorrect values 
hauls$EstSweepLngt<-hauls$SweepLngt
hauls$EstSweepLngt[hauls$SweepLngt>121&hauls$Gear=="GOV"]<-"-9"
hauls$EstSweepLngt[is.na(hauls$SweepLngt)]<-"-9"
summary(as.factor(hauls$EstSweepLngt))

# find out extent of issue
sweepsummary<-ddply(hauls, c("Survey","Country", "Year", "Quarter", "EstSweepLngt"),
                    summarise, N=length(EstSweepLngt))
summary(as.factor(hauls$Survey))
# BTS Surveys don't record a sweep - should be NA
# ROT surveys - no sweep - should be NA
# NCT surveys - no sweeps 
hauls$EstSweepLngt[hauls$Survey=="BTS"]<-NA
hauls$EstSweepLngt[hauls$Survey=="BTS-VIIa"]<-NA
hauls$EstSweepLngt[hauls$Survey=="NIGFS"]<-NA
hauls$EstSweepLngt[hauls$Survey=="PT-IBTS"]<-NA

# in 1983/1984 no country recorded sweep, but in 1985+ countries 
# reported using "Recommended Sweeps" so gonna apply the 60/110 rule to these 
# years
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Year=="1983" & hauls$DepthNew<76]<-60
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Year=="1983" &hauls$DepthNew>75]<-110
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Year=="1984" &hauls$DepthNew<76]<-60
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Year=="1984" & hauls$DepthNew>75]<-110
# Denmark: Apply standard as in Manual
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Country=="DEN" & hauls$DepthNew<76]<-60
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Country=="DEN" & hauls$DepthNew>75]<-110
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Year<2004 &
                     hauls$Quarter=="3" & hauls$Country=="DEN"& 
                     hauls$DepthNew<76]<-60
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="3"  
                   & hauls$Country=="DEN" & hauls$Year<2004 &
                     hauls$DepthNew>75]<-110

# Germany next - Q1 and Q 3 rules differ
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"& 
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Country=="GFR" & hauls$DepthNew<76]<-60
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Country=="GFR" & hauls$DepthNew>75]<-110
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Year<2004 &
                     hauls$Quarter=="3" & hauls$Country=="GFR"]<-60
#Netherlands next only 2 years missing data in quarter 1
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"&
                     hauls$Quarter=="1" & hauls$Country=="NED"]<-60
#Norway next
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"&
                     hauls$Quarter=="3" & hauls$Country=="NOR"]<-60
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Country=="NOR" & hauls$DepthNew<76]<-60
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Country=="NOR" & hauls$DepthNew>75]<-110
# Sweden
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"&
                     hauls$Quarter=="3" & hauls$Country=="SWE"]<-60
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Country=="SWE" & hauls$DepthNew<76]<-60
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Quarter=="1" &
                     hauls$Country=="SWE" & hauls$DepthNew>75]<-110
# Scotland
hauls$EstSweepLngt[hauls$Survey=="NS-IBTS"&
                     hauls$EstSweepLngt=="-9"&
                     hauls$Quarter=="1" & hauls$Country=="SCO"]<-60

# SWC Survey
hauls$EstSweepLngt[hauls$Survey=="SWC-IBTS"&
                     hauls$EstSweepLngt=="-9"& hauls$Year<2011]<-60

# Rockall
hauls$EstSweepLngt[hauls$Survey=="ROCKALL"&
                     hauls$EstSweepLngt=="-9"& hauls$Year<2011]<-60
# Check all new sweeps
sweepsummary<-ddply(hauls, c("Survey","Country", "Year", "Quarter", "EstSweepLngt"),
                    summarise, N=length(EstSweepLngt))
#Assign cat of short or long to sweep length
summary(as.factor(hauls$EstSweepLngt))
hauls$EstSweepCat<-hauls$EstSweepLngt
hauls$EstSweepCat[hauls$EstSweepLngt<61]<-"short"
hauls$EstSweepCat[hauls$EstSweepLngt==97|hauls$EstSweepLngt==110|
                    hauls$EstSweepLngt==100|hauls$EstSweepLngt==120]<-"long"


sweepcatsummary<-ddply(hauls, c("Survey","Country", "Year", "Quarter", "EstSweepCat"),
                       summarise, N=length(EstSweepCat))
################
# GROUND SPEED #
################
##Convert from nautical miles/hour to meters/minute
str(hauls)
#make a plot to look at the current groundspeed*time against distance 
# if perfect we expect an intercept of 0 and a slope of 1
png(file = "distance_speed_time_differences_26-05-2016.png", bg = "transparent")
par(xpd=FALSE)
plot(hauls$GroundSpeed*1852/60*hauls$HaulDur, hauls$Distance, 
     pch=19, col="black", cex=0.5, xlab="Speed X Time", ylab="Distance")
abline(a=0, b=1, col="lightgrey", lwd=2)
dev.off()
# Change the confidence interval fill color
png(file = "distance_speed_time_differences_with_CI_26-05-2016.png", bg = "transparent")
p1<-ggplot(hauls, aes(x=hauls$GroundSpeed*1852/60*hauls$HaulDur,
                      y=hauls$Distance)) + 
  geom_point(shape=18, color="black")+
  geom_smooth(method=lm,  linetype="dashed",
              color="lightgrey", fill="darkgrey", se=TRUE, fullrange=FALSE, level=.95)
p1 + scale_color_grey()+theme_classic()
dev.off()

# check ground speed
png(file="groundspeed_boxplot_26-05-2016.png", bg="transparent")
plot(hauls$Survey, hauls$GroundSpeed, pch=19, xlab="Survey", 
     ylab="GroundSpeed (knots)", col="lightgrey")
dev.off()
# outliers in Groundspeed found
check<-hauls[hauls$GroundSpeed<3|hauls$GroundSpeed>5, ]
png(file="groundspeed_distance_comparision_26-05-2016.png", bg="transparent")
plot(check$GroundSpeed*check$HaulDur*1852/60, check$Distance, pch=19, col="black")
dev.off()
# In Ns-IBTS 1995 it seems some of the french ground speeds are in the Speed Water Column
# and the Speed water is in the Ground Speed Col.
hauls$GroundSpeed[hauls$UniqueID=="NS-IBTS/1995/1/THA/2/GOV"]<-4
hauls$SpeedWater[hauls$UniqueID=="NS-IBTS/1995/1/THA/2/GOV"]<-2
hauls$GroundSpeed[hauls$UniqueID=="NS-IBTS/1995/1/THA/3/GOV"]<-4
hauls$SpeedWater[hauls$UniqueID=="NS-IBTS/1995/1/THA/3/GOV"]<-2
hauls$GroundSpeed[hauls$UniqueID=="NS-IBTS/1995/1/THA/6/GOV"]<-4
hauls$GroundSpeed[hauls$UniqueID=="NS-IBTS/1995/1/THA/9/GOV"]<-3.8
hauls$SpeedWater[hauls$UniqueID=="NS-IBTS/1995/1/THA/9/GOV"]<-1.9
hauls$GroundSpeed[hauls$UniqueID=="NS-IBTS/1995/1/THA/11/GOV"]<-3.9
hauls$SpeedWater[hauls$UniqueID=="NS-IBTS/1995/1/THA/11/GOV"]<-1.9

# in three cases the ground speed is recorded as zero - change to NA
list<-c('SP_ARSA/1995/1/CDS/23/BAK', 'SP_ARSA/1995/1/CDS/25/BAK',
        'SP_ARSA/1995/1/CDS/30/BAK')

hauls$GroundSpeed[hauls$UniqueID%in%list]<-NA
# really fast ground speed check outlat long distance matches but in others it was way out
#check<-hauls[hauls$GroundSpeed<3|hauls$GroundSpeed>5 
gs_dat<-subset(hauls, !is.na(GroundSpeed),)
  gs1<-lm(GroundSpeed~Quarter:Ship+DepthNew:Ship+ Gear:Ship, data=gs_dat)
  gs2<-lm(GroundSpeed~Quarter:Ship+DepthNew:Ship, data=gs_dat)
  gs3<-lm(GroundSpeed~Quarter:Ship+DepthNew:Gear, data=gs_dat)
    summary(gs1)
      anova(gs3, gs2, gs1)
      anova(gs1)
          AIC(gs1)
          AIC(gs2)
          AIC(gs3)
# is everything significant cause its a realy big data set (30239 obs)
# check the signifiance levels are real use a random selection of data 
  # gs_sample<-gs_dat[sample(1:nrow(gs_dat), 100, replace=FALSE)]
      #gs1<-lm(GroundSpeed~Quarter:Ship+DepthNew:Ship+ Gear:Ship, data=gs_sample)
      #gs2<-lm(GroundSpeed~Quarter:Ship+DepthNew:Ship, data=gs_sample)  
      #gs3<-lm(GroundSpeed~Quarter:Ship+DepthNew:Gear, data=gs_sample)
          #anova(gs3, gs2, gs1)
          #anova(gs1)
          #AIC(gs1)
          # AIC(gs2)
          #AIC(gs3)

# draw a graph showing predicted v actual ground speeds.

png(file="groundspeed_predictedVactual_27-05-2016.png", bg="transparent")
predict<-predict(gs1)
gs<-subset(hauls, !is.na(hauls$GroundSpeed),)
plot(predict, gs$GroundSpeed, xlab="Predicted GroundSpeed (knots)",
     ylab="Recorded Groundspeed (knots)", pch=19)
abline(0,1, col="lightgrey")
dev.off()
# GROUNDSPEED NOT RECORDED BUT DISTANCE AND DURATION RECORDED
hauls$Estimated_groundspeed<-hauls$Distance/hauls$HaulDur/1852*60
summary(hauls$Estimated_groundspeed)
png(file="groundspeed_predictedVdistance_divided_by_time_27-05-2016.png", bg="transparent")
plot(hauls$Estimated_groundspeed, hauls$GroundSpeed, 
     pch=19, col="lightgrey",
     xlim=c(1,6), ylim=c(1,6))
abline(0,1, col="black")
dev.off()
# no surprises here!
# useing model with r squared of ~0.75 and "best" AIC score
gs1<-lm(GroundSpeed~Quarter:Ship+DepthNew:Ship+ Gear:Ship, data=hauls)
# pretty decent model here - problem is it won't work for all ships as I have some 
# ships with no data at all on Ground speed to inform model
summary(hauls$GroundSpeed)
needSpeed <- hauls[is.na(hauls$GroundSpeed),]
needSpeedShip <- unique(needSpeed$Ship)
withSpeedShip <- unique(hauls$Ship[!is.na(hauls$GroundSpeed)])

# ID ships that have some missing GroundSpeed records
canSpeedShip <- needSpeedShip[needSpeedShip %in% withSpeedShip]
canSpeed <- hauls[Ship %in% canSpeedShip, ]
#
# Split the data into the two types: only a few missing and completely missing
canSpeedNA <- canSpeed[is.na(GroundSpeed) & is.na(Distance),]
canSpeedOK <- canSpeed[!is.na(GroundSpeed),]

gs2<-lm(GroundSpeed~Quarter+DepthNew+Gear, data=hauls)
summary(gs2)
AIC(gs1, gs2)
anova(gs1,gs2)
predictedGS<-predict(gs2, hauls, allow.new.levels=T)
# allmissing observations

canSpeed$predicted_groundspeed_gs1<-predict(gs1, canSpeed , allow.new.levels=T)
summary(canSpeed$predicted_groundspeed_gs1)
plot(canSpeed$predicted_groundspeed_gs1,canSpeed$GroundSpeed, pch=19, col='grey' )
canSpeed$predicted_groundspeed_gs2<-predict(gs2, canSpeed , allow.new.levels=T)
plot(canSpeedNA$predicted_groundspeed,canSpeedNA$Distance*canSpeedNA$HaulDur*1852/60, 
     pch=19, col='grey' )
canSpeed$predicted_groundspeed_gs2<-predict(gs2, canSpeed , allow.new.levels=T)

# attach predictions to the hauls dataset
gs_dat$predicted_groundspeed_gs2<-predict(gs2, gs_dat, allow.new.levels=T)
gs_dat$predicted_groundspeed_gs1<-predict(gs1, gs_dat, allow.new.levels=T)
list<-canSpeed$UniqueID

hauls$predicted_groundspeed_gs2[hauls$UniqueID%in%list]<-canSpeed$predicted_groundspeed_gs2[hauls$UniqueID%in%list]
hauls$predicted_groundspeed_gs1[hauls$UniqueID%in%list]<-canSpeed$predicted_groundspeed_gs1[hauls$UniqueID%in%list]
# second list merged
list<-canSpeed$UniqueID
hauls$predicted_groundspeed_gs1[hauls$UniqueID%in%list]<-canSpeed$predicted_groundspeed_gs1[hauls$UniqueID%in%list]

list<-canSpeed$UniqueID
hauls$predicted_groundspeed_gs2[hauls$UniqueID%in%list]<-canSpeed$predicted_groundspeed_gs2[hauls$UniqueID%in%list]

summary(hauls$Distance[hauls$Gear=="ROT"]/hauls$HaulDur[hauls$Gear=="ROT"]/1852*60)
summary(hauls$predicted_groundspeed_gs2)

hauls$GroundSpeed_Used<-hauls$GroundSpeed
hauls$GroundSpeed_Quality_Code<-"Recorded_Groundspeed"
hauls$GroundSpeed_Quality_Code[is.na(hauls$GroundSpeed_Used)]<-"model_1"
hauls$GroundSpeed_Used[is.na(hauls$GroundSpeed_Used)]<-hauls$predicted_groundspeed_gs1[is.na(hauls$GroundSpeed_Used)]
hauls$GroundSpeed_Quality_Code[is.na(hauls$GroundSpeed_Used)]<-"model_2"
hauls$GroundSpeed_Used[is.na(hauls$GroundSpeed_Used)]<-hauls$predicted_groundspeed_gs2[is.na(hauls$GroundSpeed_Used)]
hauls$GroundSpeed_Quality_Code[is.na(hauls$GroundSpeed_Used)]<-"Distance_Time_Esimate"
hauls$GroundSpeed_Used[is.na(hauls$GroundSpeed_Used)]<-hauls$Estimated_groundspeed[is.na(hauls$GroundSpeed_Used)]

summary(hauls$GroundSpeed_Used)

# Still Some Blanks in Data - BTS and early years
gsDat <- hauls[is.na(hauls$GroundSpeed), ]
head( gsDat)
gs3<-lm(GroundSpeed~Quarter+DepthNew, data=hauls)
summary(gs3)
AIC(gs1,gs2, gs3)
anova(gs1,gs2,gs3)

gsDatLen <- nrow(gsDat)
hauls$predicted_groundspeed_gs3<-predict(gs3, hauls , allow.new.levels=T)
summary(hauls$predicted_groundspeed_gs3)


hauls$GroundSpeed_Quality_Code[is.na(hauls$GroundSpeed_Used)]<-"model_3"
hauls$GroundSpeed_Used[is.na(hauls$GroundSpeed_Used)]<-hauls$predicted_groundspeed_gs3[is.na(hauls$GroundSpeed_Used)]


summary(hauls$GroundSpeed_Used)

hauls[, GroundSpeed_meters_per_min := GroundSpeed_Used * 1852 / 60]
summary(hauls$GroundSpeed_meters_per_min)
###################
# DISTANCE HAULED #
###################


## Calculate haversine distance with shoot and haul coordinates ##
hauls[, LatLongDistance := earth.dist(long1 = ShootLong,
                                      lat1 = ShootLat,
                                      long2 = HaulLong,
                                      lat2 = HaulLat) * 1000]

## RAW DISTANCE ##
hauls[!is.na(Distance), c("newDist", "qualityDistance") :=
        list(Distance, "rawDistance")]

## HAVERSINE DISTANCE ##
# if haul and shoot coordinates are the same (i.e., equal to zero) then leave as NA
# Also ingore hauls with funny implied speed.
hauls[is.na(Distance) & !is.na(LatLongDistance) & LatLongDistance > 1 &
        LatLongDistance/HaulDur>60 & LatLongDistance/HaulDur<200 ,
      c("newDist", "qualityDistance") :=
        list(LatLongDistance, "LatLongDistance")]

## DURATION X SPEED ##
# HaulDur x GroundSpeed
hauls[, SpeedTimeDist := hauls$GroundSpeed_meters_per_min*HaulDur]

hauls[ !is.na(SpeedTimeDist) &is.na(newDist),
      c("newDist", "qualityDistance") :=
        list( SpeedTimeDist, "SpeedHaulDur")]

# Hauls that don't have raw distance, shoot/haul coordinates, or GroundSpeed can be estimated
# using linear models to predict GroundSpeed. Two different types of missing data are found:
# 1) ships that have no GroundSpeed records and we need to estimate from other ships, and
# 2) ships that have only a few missing GroundSpeed records and we can use ship as a factor in the lm
# Model for estimating Ground Speed has been reviewed based on feedback 
# from the IBTS working Group (V.T)
summary(as.numeric(hauls$newDist))

# check new distances relationships
png(file = "distance_speed_time_differences.png", bg = "transparent")
par(xpd=FALSE)
plot(hauls$SpeedTimeDist, hauls$newDist, 
     pch=19, col="black", cex=0.5, xlab="Speed X Time", ylab="Distance")
abline(a=0, b=1, col="lightgrey", lwd=2)
dev.off()

# distance checks required as some of them are really odd.
hauls$LatLongDistance[hauls$LatLongDistance==0]<-NA
mad_diferent<-subset(hauls, hauls$newDist/hauls$SpeedTimeDist<.75|
                       hauls$newDist/hauls$SpeedTimeDist>1.25|
                       hauls$newDist/hauls$LatLongDistance<.75|
                       hauls$newDist/hauls$LatLongDistance>1.25,
                     )
# only 2854 to check :)
# if lat long distance is close to raw distance used then its okay to use these
summary(mad_diferent$newDist)
okay_distance<-subset(mad_diferent,
                      mad_diferent$newDist/mad_diferent$LatLongDistance>.75|
                      mad_diferent$newDist/mad_diferent$LatLongDistance<1.25,
)
okay_distance<-subset(okay_distance, okay_distance$qualityDistance=="rawDistance",)
# 2124of these checks are fine lat long and raw match so we will use
list<-okay_distance$UniqueID
mad_diferent1<-subset(mad_diferent, !UniqueID%in%list,)
# 730 still to check
okay_speed<-subset(mad_diferent1,
                   mad_diferent1$newDist/mad_diferent1$SpeedTimeDist>.75|
                     mad_diferent1$newDist/mad_diferent1$SpeedTimeDist<1.25,
)
okay_speed<-subset(okay_speed, okay_speed$qualityDistance=="rawDistance",)
# anothe 305 are okay 
list<-okay_speed$UniqueID
mad_diferent2<-subset(mad_diferent1, !UniqueID%in%list,)
# leaves 425 distances that are mis matches by more than 25%

# check implied groudspeed of lat long distances recorded in mad_different2
mad_diferent2$funny_speed_implied<-(mad_diferent2$LatLongDistance/mad_diferent2$HaulDur/1852*60)
summary(mad_diferent2$funny_speed_implied)
funny_speeds<-subset(mad_diferent2, funny_speed_implied<2|funny_speed_implied>6.5,)
summary(mad_diferent2$funny_speed_implied[mad_diferent2$qualityDistance=="SpeedHaulDur"])
summary(mad_diferent2$funny_speed_implied[mad_diferent2$qualityDistance=="LatLongDistance"])
# all distances in newDist are withing acceptable ranges the best estimate is applied in
# each situation
#where latlongdistance is acceptable it is used where is is not within the acceptable 
#ranges it isn't used and speed is used!
summary(hauls$newDist)
# save a copy of hauls at this point
write.csv(hauls, "Working_hauls_file_18_05_2016.csv")
# remove all the intermediate files 
rm(belgium, canSpeed, canSpeedOK, canSpeedNA, canSpeedShip, Car_ship, check, cname,
   cols, delete_ship, cnames, den, files, funny_speeds, funny_speed_implied, gs, gs_dat,
   gsDatLen, i, invalidhauls, keepers, landlocked, largehauls, list,
   long_error, mad_diferent2, mad_diferent1, mad_diferent, needSpeedShip, needSpeed,
   okay_speed, okay_distance, others, p1, pre1983, predict, quater2or4, quaterscheck,
   sco, smallhauls, SOL_ship, sweepcatsummary, sweepsummary, withSpeedShip, non_standard_gear,
   NOAA_Depth)
summary(hauls$newDist)
#####################################################
# DoorSpread NCT # # WingSpread NCT# Netopening NCT #
#####################################################
# No sensors on this gear so mean is applied as supplied by ICES 2010
# DoorSpread 45.7m
hauls$DoorSpread[hauls$Gear=="NCT"]<- 45.7
# WingSpread = 15.1
hauls$WingSpread[hauls$Gear=="NCT"]<-15.1
# netopening 4.6m
hauls$Netopening[hauls$Gear=="NCT"]<-4.6
# set up user values
hauls$Use_DoorSpread[hauls$Gear=="NCT"]<-45.7
hauls$QualityDoor[hauls$Gear=="NCT"]<-"mean_doorspread"
hauls$Use_WingSpread[hauls$Gear=="NCT"]<-15.1
hauls$QualityWing[hauls$Gear=="NCT"]<-"mean_wingspread"
hauls$Use_Netopening[hauls$Gear=="NCT"]<-4.6
hauls$QualityNet[hauls$Gear=="NCT"]<-"mean_netopening"
summary(hauls$Use_Netopening[hauls$Gear=="NCT"])
###################################################
# DoorSpread BT # # WingSpread BT# Netopening BT #
##################################################
# Beams have a set "wing spread" so set wing and door as the set width
# net opening will be set to NA
summary(as.factor(hauls$Gear))
# Netherlands
# DoorSpread 8m (BTS manual 2009)
hauls$DoorSpread[hauls$Gear=="BT8"]<- 8
# WingSpread = 8
hauls$WingSpread[hauls$Gear=="BT8"]<-8
# netopening NA
hauls$Netopening[hauls$Gear=="BT8"]<-NA
# Germany 
# DoorSpread 7.2m (BTS manual 2009)
hauls$DoorSpread[hauls$Gear=="BT7"]<-7.2
# WingSpread = 7.2
hauls$WingSpread[hauls$Gear=="BT7"]<-7.2
# netopening NA
hauls$Netopening[hauls$Gear=="BT8"]<-NA
# UK  (BTS manual 2009)
# DoorSpread 7.2m (BTS manual 2009)
hauls$DoorSpread[hauls$Gear=="BT4A"]<-4
# WingSpread = 7.2
hauls$WingSpread[hauls$Gear=="BT4A"]<-4
# netopening NA
hauls$Netopening[hauls$Gear=="BT4A"]<-NA
# setup user values 
hauls$Use_DoorSpread[hauls$Gear=="BT4A"]<-4
hauls$QualityDoor[hauls$Gear=="BT4A"]<-"raw_doorspread"
hauls$Use_WingSpread[hauls$Gear=="BT4A"]<-4
hauls$QualityWing[hauls$Gear=="BT4A"]<-"raw_wingspread"
hauls$Use_Netopening[hauls$Gear=="BT4A"]<-1
hauls$QualityNet[hauls$Gear=="BT4A"]<-"No_netopening"

hauls$Use_DoorSpread[hauls$Gear=="BT7"]<-7.2
hauls$QualityDoor[hauls$Gear=="BT7"]<-"raw_doorspread"
hauls$Use_WingSpread[hauls$Gear=="BT7"]<-7.2
hauls$QualityWing[hauls$Gear=="BT7"]<-"raw_wingspread"
hauls$Use_Netopening[hauls$Gear=="BT7"]<-1
hauls$QualityNet[hauls$Gear=="BT7"]<-"No_netopening"

hauls$Use_DoorSpread[hauls$Gear=="BT8"]<-8
hauls$QualityDoor[hauls$Gear=="BT8"]<-"raw_doorspread"
hauls$Use_WingSpread[hauls$Gear=="BT8"]<-8
hauls$QualityWing[hauls$Gear=="BT8"]<-"raw_wingspread"
hauls$Use_Netopening[hauls$Gear=="BT8"]<-1
hauls$QualityNet[hauls$Gear=="BT8"]<-"No_netopening"

summary(hauls$Use_WingSpread[hauls$Gear=="BT4A"])
#####################################################
# DoorSpread ROT # # WingSpread ROT# Netopening ROT #
#####################################################
summary(hauls$DoorSpread[hauls$Gear=="ROT"])
summary(hauls$WingSpread[hauls$Gear=="ROT"])
summary(hauls$Netopening[hauls$Gear=="ROT"])
# Doorspread can be sorted first
#################################
# DoorSpread only has 955 missing values to be estimated
png(file = "doorspread_ROT_27-05-2016.png", bg = "transparent")
plot(hauls$Depth[hauls$Gear=="ROT"], hauls$DoorSpread[hauls$Gear=="ROT"], 
     pch=19, xlab="Depth (m)",
     ylab="Door Spread (m)")
dev.off()
# raw data looks good - no worrying outliers
corrhaul_rot<-subset(hauls, Gear=="ROT",
                 select=c(Year, Depth, Distance,
                          DoorSpread))
summary(corrhaul_rot)
require(corrgram)
png(file = "corrhaul_ROT_27-05-2016.png", bg = "transparent")
corrgram(corrhaul_rot, order="PCA", lower.panel=panel.shade,
         upper.panel=panel.pie, text.panel=panel.txt,
         main="Hauls Data NI") 
dev.off()
# the only variable available to estimate doorspread is depth for ROT ship
# no sweep, no changes in gear , no wing or netopening
fm1<-lm(log(DoorSpread[hauls$Gear=="ROT"])~log(Depth[hauls$Gear=="ROT"]), data=hauls)
AIC(fm1)
summary(fm1)
# AIC in door_lm2 is better
coeff=coefficients(fm1); coeff
png(file = "logged_doorspread_ROT_27-05-2016.png", bg = "transparent")
plot(log(hauls$DepthNew[hauls$Gear=="ROT"]), log(hauls$DoorSpread[hauls$Gear=="ROT"]), pch=19, xlab="logged Depth (m)",
     ylab="logged Doorspread (m)")
abline(a=(2.556167), b=(0.261593) , col="red", lwd=2)
dev.off()

hauls$mod_doorspread_rot[hauls$Gear=="ROT"]<-exp(coeff[1]+coeff[2]*log(hauls$DepthNew[hauls$Gear=="ROT"]))
################################################
# set up user values for doorspread
hauls$Use_DoorSpread[!is.na(hauls$DoorSpread)&
                       hauls$Gear=="ROT"]<-hauls$DoorSpread[!is.na(hauls$DoorSpread)&
                                                              hauls$Gear=="ROT"]
hauls$QualityDoor[!is.na(hauls$DoorSpread)&hauls$Gear=="ROT"]<-"raw_doorspread"
hauls$Use_DoorSpread[is.na(hauls$DoorSpread)&hauls$Gear=="ROT"]<-hauls$mod_doorspread_rot[is.na(hauls$DoorSpread)&hauls$Gear=="ROT"]
hauls$QualityDoor[is.na(hauls$DoorSpread)&hauls$Gear=="ROT"]<-"model_doorspread_rot"

summary(hauls$mod_doorspread_rot[hauls$Gear=="ROT"])
summary(hauls$Use_DoorSpread[hauls$Gear=="ROT"])
#############
#wing spread#
#############
# deal with wingspread next

summary(hauls$WingSpread[hauls$Gear=="ROT"])
# 2333 estimated values needed
# Matt sent me some trail wingspreads to help to model these data
# but data now available in DATRAS file 20 values available
# lets look at these data first
png(file = "wingspread_ROT_27-05-2016.png", bg = "transparent")
plot(hauls$DepthNew[hauls$Gear=="ROT"],hauls$WingSpread[hauls$Gear=="ROT"],
     pch=19, xlab="Depth (m)",
     ylab="Wingspread (m)" )
abline(lm(hauls$WingSpread[!is.na(hauls$WingSpread)&hauls$Gear=="ROT"]~
           hauls$DepthNew[!is.na(hauls$WingSpread)&hauls$Gear=="ROT"]),
      col="lightgrey")
dev.off()

png(file = "doorVwing_ROT_27-05-2016.png", bg = "transparent")
plot(hauls$Use_DoorSpread[hauls$Gear=="ROT"],hauls$WingSpread[hauls$Gear=="ROT"],
     pch=19, xlab="Doorspread (m)",
     ylab="Wingspread (m)" )
abline(lm(hauls$WingSpread[!is.na(hauls$WingSpread)&hauls$Gear=="ROT"]~
            hauls$Use_DoorSpread[!is.na(hauls$WingSpread)&hauls$Gear=="ROT"]),
       col="lightgrey")
dev.off()
#############
# run models 
# Type: Linear model 
# subset data for ease of modeling
# given how data poor the situation is this must be kept very simple
ws_dat<-subset(hauls, !is.na(hauls$WingSpread) & hauls$Gear=="ROT", )

fm1 <- lm(log(WingSpread) ~ log(DepthNew)
              + log(Netopening)
              + log(DoorSpread)
              + log(DepthNew)*log(DoorSpread), data=ws_dat)
summary(fm1)
# least significant thing is the interaction term - remove 
fm1 <- lm(log(WingSpread) ~ log(DepthNew)
          + log(Netopening)
          + log(DoorSpread), data=ws_dat)
summary(fm1)
step(fm1)
fm1 <- lm(log(WingSpread) ~ log(DoorSpread), data=ws_dat)
summary(fm1)
#####
# Full model: lm(log(MeanWingSpread) ~ log(MeanDoorSpread), data=wing)
# Great we can keep this really simple and have a really strong
# Adjusted R sqd of 0.952
# has the best AIC score (-153.47.6)
# because the actual data has 20 wingspread values
# the estimated simple regression equation will be applied.
coeffs=coefficients(fm1); coeffs

ws=coeffs[1]+coeffs[2]*log(ws_dat$DoorSpread)
ws=exp(coeffs[1]+coeffs[2]*log(28.57672))
hauls$EstWingSpread<-exp(ws)
hauls$mod_wingspread_rot[hauls$Gear=="ROT"]<-exp(0.3798356+0.6489731*log(hauls$Use_DoorSpread[hauls$Gear=="ROT"]))
################################################
# set up user values for doorspread
#RAW WINGSPREAD
hauls$Use_WingSpread[!is.na(hauls$WingSpread)&hauls$Gear=="ROT"]<-hauls$WingSpread[!is.na(hauls$WingSpread)&hauls$Gear=="ROT"]
hauls$QualityWing[!is.na(hauls$WingSpread)&hauls$Gear=="ROT"]<-"raw_wingspread"
hauls$Use_WingSpread[is.na(hauls$WingSpread)&hauls$Gear=="ROT"]<-hauls$mod_wingspread_rot[is.na(hauls$WingSpread)&hauls$Gear=="ROT"]
hauls$QualityWing[is.na(hauls$WingSpread)&hauls$Gear=="ROT"]<-"model_wingspread_rot"

summary(hauls$mod_wingspread_rot[hauls$Gear=="ROT"])
summary(hauls$Use_WingSpread[hauls$Gear=="ROT"])
############
#Netopening# 
############
# on the merry-go-round again lets do netopening.
summary(hauls$Netopening[hauls$Gear=="ROT"])
# 2292 estimated values needed
# Matt sent me some trail data to help to model these data
# but data now available in DATRAS file 20 values available
# lets look at these data first
png(file = "netopening_ROT_27-05-2016.png", bg = "transparent")
plot(hauls$DepthNew[hauls$Gear=="ROT"],hauls$Netopening[hauls$Gear=="ROT"],
     pch=19, xlab="Depth (m)",
     ylab="Net opening (m)" )
abline(lm(hauls$Netopening[!is.na(hauls$Netopening)&hauls$Gear=="ROT"]~
            hauls$DepthNew[!is.na(hauls$Netopening)&hauls$Gear=="ROT"]),
       col="lightgrey")
dev.off()
# no major outliers
png(file = "doorVnet_ROT_27-05-2016.png", bg = "transparent")
plot(hauls$Use_DoorSpread[hauls$Gear=="ROT"],hauls$Netopening[hauls$Gear=="ROT"],
     pch=19, xlab="Doorspread (m)",
     ylab="Net opening (m)" )
abline(lm(hauls$Netopening[!is.na(hauls$Netopening)&hauls$Gear=="ROT"]~
            hauls$Use_DoorSpread[!is.na(hauls$Netopening)&hauls$Gear=="ROT"]),
       col="lightgrey")
dev.off()
#############
# run models 
# Type: Linear model 
# subset data for ease of modeling
# given how data poor the situation is this must be kept very simple
no_dat<-subset(hauls, !is.na(hauls$Netopening) & hauls$Gear=="ROT", )
names(no_dat)
# 62 obs
fm1 <- lm(log(Netopening) ~ log(DepthNew)
          + log(WingSpread)
          + log(DoorSpread), data=no_dat)
summary(fm1)
step(fm1)
# Depth and Wing are equally poor- remove wing cause thats mostly modeled data 
fm1 <- lm(log(Netopening) ~ log(DepthNew), data=no_dat)
summary(fm1)
step(fm1)
# Not enough data to model this attribute - either use mean value or don't do 
# vol estimates with ROT gear - similar to Beam gears!
# Matt sent me the Standard Gear Specs- IBTS Report 2013
hauls$Use_Netopening[!is.na(hauls$Netopening)&
                       hauls$Gear=="ROT"]<-hauls$Netopening[!is.na(hauls$Netopening)&
                                                              hauls$Gear=="ROT"]
hauls$QualityNet[!is.na(hauls$Netopening)&
                       hauls$Gear=="ROT"]<-"raw_netopening"
hauls$Use_Netopening[is.na(hauls$Netopening)&hauls$Gear=="ROT"]<-3
hauls$QualityNet[is.na(hauls$Netopening)&hauls$Gear=="ROT"]<-"mean_netopening"
summary(hauls$Use_Netopening[hauls$Gear=="ROT"])
####################################################################
# DoorSpread BAK/PORC # # WingSpread BAK/PORC# Netopening BAK/PORC #
####################################################################
# Explore data first #
######################
# I'm going to look at Porc baka and the regular baka together and see can one model 
# do both gears with reasonable results
# subest data to look at it easier
spain<-subset(hauls, Country=="SPA",)
png(file = "QQ_doorspread_spain_27-05-2016.png", bg = "transparent")
qqnorm(spain$DoorSpread, main="Normal QQ plot for DoorSpread", ylab="DoorSpread (m)")
qqline(spain$DoorSpread, col="red")
dev.off()
#
png(file = "QQ_wingspread_spain_27-05-2016.png", bg = "transparent")
qqnorm(spain$WingSpread, main="Normal QQ plot for WingSpread", ylab="WingSpread (m)")
qqline(spain$WingSpread, col="red")
dev.off()
png(file = "QQ_netopening_spain_27-05-2016.png", bg = "transparent")
qqnorm(spain$Netopening, main="Normal QQ plot for Netopening", ylab="Netopening (m)")
qqline(spain$Netopening, col="red")
dev.off()
# couple of outliers needing a closer look in netopeing
png(file = "netopening_spain_27-05-2016.png", bg = "transparent")
plot(spain$DepthNew, spain$Netopening, pch=19, col='grey', xlab="Depth (m)", 
     ylab="Net Opening (m)")
dev.off()
# plot shows doorspread is normally distributed as the points fall close to the line
png(file = "doorspread_spain_27-05-2016.png", bg = "transparent")
plot(spain$DepthNew, spain$DoorSpread, pch=19, col='grey', xlab="Depth (m)", 
     ylab="Door Spread (m)")
dev.off()
png(file = "wingspread_spain_27-05-2016.png", bg = "transparent")
plot(spain$Depth, spain$WingSpread, pch=19, col='grey', xlab="Depth (m)", 
     ylab="Wing Spread (m)")
dev.off()
# use a box plot to look at the effect of one variable against another, 
png(file = "doorspread_spain_box_27-05-2016.png", bg = "transparent")
boxplot(spain$DoorSpread~spain$Ship,
        col="lightgray", xlab="Ship", ylab="DoorSpread (m)",
        ylim=c(30, 150))
dev.off()
png(file = "wingspread_spain_box_27-05-2016.png", bg = "transparent")
boxplot(spain$WingSpread~spain$Ship, 
        col="lightgray", xlab="Ship", ylab="WingSpread (m)",
        ylim=c(10, 32))
dev.off()
# boxplot reveals that some ships have a lower average doorspread than others, 
# wingspreads of some ships, like are more variable than others. 
# a clear ship effect exists - decision to include ship as factor in model 
png(file = "doorVsweep_spain_box_27-05-2016.png", bg = "transparent")
boxplot(spain$DoorSpread~spain$SweepLngt,
        col="lightgray", xlab="Sweep Length (m)", ylab="DoorSpread (m)",
        ylim=c(30, 200))
dev.off()

png(file = "wingVsweep_spain_box_27-05-2016.png", bg = "transparent")
boxplot(spain$WingSpread~spain$SweepLngt,   col="lightgray", 
        xlab="Sweep Length (m)", ylab="WingSpread (m)",
        ylim=c(10, 32))
dev.off()
# Variation is similar to that seen in ship effect - which probably explains this better
# Sweep Lnght has a stronger effect on DoorSpread than Wing Spread, look at 2 cats,
# Short and Long Sweep to see if this may give sufficent explaniation of the variation
# in the model 
# boxplot reveals that sweep impacts on doorspread, 
# as the sweep increases so too does the doorspread this is related to depth too!
# this is captured by the long/ short catagories too.
summary(as.factor(spain$Gear))
# no Gear Exceptions in spain
# but two different gears
png(file = "wingVgear_spain_box_27-05-2016.png", bg = "transparent")
boxplot(spain$WingSpread~spain$Gear, col="lightgrey", pch=19,
        xlab="Gear", ylab="WingSpread (m)")
dev.off()
png(file = "doorVgear_spain_box_27-05-2016.png", bg = "transparent")
boxplot(spain$DoorSpread~spain$Gear, col="lightgrey", pch=19,
        xlab="Gear", ylab="Door Spread (m)")
dev.off()

cols<-c(rainbow(3))
png(file="doorspreadVDepth_spain_col_27-05-2016.png", bg="transparent")
plot(spain$Depth, spain$DoorSpread, col=cols[as.factor(spain$Gear)], pch=20)
legend(680, 90, levels(as.factor(spain$Gear)), col=cols, 
       pch=15, ncol=1, cex=1, bty="n")
dev.off()
png(file="wingspreadVDepth_spain_col_27-05-2016.png", bg="transparent")
plot(spain$Depth, spain$WingSpread, col=cols[as.factor(spain$Gear)], pch=20)
legend(680, 30, levels(as.factor(spain$Gear)), col=cols, 
       pch=15, ncol=1, cex=1, bty="n")
dev.off()

# stations look good - Scotland may have fished with the Irish DWS in some years?
plot3d( spain$Depth, spain$ShootLong, spain$ShootLat,  main= "Station Locations",
        col=cols[as.factor(spain$Gear)] , pch=20)
summary(spain$ShootLat)
summary(spain$ShootLong)

# Deeper depths look like they are in the correct places
png(file="other_spainish_grahps_27-05-2016.png", bg="transparent")
par(mfrow=c(2,3))
plot(spain$WingSpread, spain$DoorSpread, col=cols[as.factor(spain$Gear)], pch=20)
legend(1900, 160, levels(as.factor(spain$Gear)), col=cols, 
       pch=15, ncol=1, cex=.9, bty="n")
#Look at relationship between Warp andf Door
plot(spain$Warplngt, spain$DoorSpread, col=cols[as.factor(spain$Gear)], pch=20)
legend(1900, 160, levels(as.factor(spain$Gear)), col=cols, 
       pch=15, ncol=1, cex=.9, bty="n")
# Very Similar to Depth, DoorSpread relationship
plot(spain$Warplngt, spain$WingSpread, col=cols[as.factor(spain$Gear)], pch=20)
legend(1900, 160, levels(as.factor(spain$Gear)), col=cols, 
       pch=15, ncol=1, cex=.9, bty="n")
# Very Similar to Depth, WingSpread relationship
plot(spain$Depth,spain$Warplngt, col=cols[as.factor(spain$Gear)], pch=20)
legend(650, 1800, levels(as.factor(spain$Gear)), col=cols, 
       pch=15, ncol=1, cex=.9, bty="n")
plot(spain$Netopening,spain$DoorSpread, col=cols[as.factor(spain$Gear)], pch=20, xlim=c(0,5))
plot(spain$Netopening,spain$WingSpread, col=cols[as.factor(spain$Gear)], pch=20, xlim=c(0,5))
legend(4, 25, levels(as.factor(spain$Gear)), col=cols, 
       pch=15, ncol=1, cex=.9, bty="n")
# Pearson's product-moment correlation

cor.test(spain$Warplngt,spain$Depth) # 0.9862778
cor.test(spain$DoorSpread,spain$Depth) # 0.7596876 
cor.test(spain$WingSpread,spain$Depth) # 0.5695914

# Subset data to check correlations


corhaul<-subset(spain,
                select=c(SweepLngt, Year, Depth, 
                         Netopening, Warplngt,
                         DoorSpread, WingSpread))

rcorr(as.matrix(corhaul), type="pearson")

corrgram(corhaul, order=TRUE, lower.panel=panel.shade,
         upper.panel=panel.pie, text.panel=panel.txt,
         main="IBTS Haul Parameters") 

corrgram(corhaul, order=TRUE, lower.panel=panel.ellipse,
         upper.panel=panel.pts, text.panel=panel.txt,
         diag.panel=panel.minmax,
         main="IBTS Haul Parameters", 
         pch=19) 
# depth and warp are showing a positive linear relationship.
# Corrgram shows relationsships and correlations

# run a generalised linear model
# Response Variable: DoorSpread
# Fixed Effects: Depth, Warp Length, Wing Spread, Sweep Length, Net Opening,
#               Ship, Ground Gear, Survey, Quarter, Year, StatRec
# does quater account for some differences in weather patterns at each stage of the 
# year???
summary(as.factor(Quarter))
boxplot(spain$DoorSpread~as.factor(spain$Quarter),
        col="lightgray", xlab="Quarter", ylab="DoorSpread (m)")
boxplot(spain$WingSpread~as.factor(spain$Quarter),
        col="lightgray", xlab="Quarter", ylab="DoorSpread (m)")
# Again the quaters look different - but is this to do with the ships that are 
# fishing or the weather?
plot(spain$Quarter, spain$DoorSpread, col=cols[as.factor(spain$Gear)],
     pch=19, xlim=c(1,5))
# more likely related to gear than quarter
######################################################
# need to explore what the minimun 
# adequate model is. 

# Fit non multi level models
options(show.signif.stars = T)

# Find minimal adequate model

# DoorSpread is normally a good predictor of wingspread. In this case
# doorsoread data isn't available alongside wingspread very often (80 cases), 
# thus we must use other parameters in our model. 
library(lmerTest)
#Center data to give model stability 
spain[!is.na(Depth), c("meanDepth") :=
           mean(Depth)]
spain[!is.na(WingSpread), c("meanWingSpread") :=
           mean(WingSpread)]
spain[!is.na(Netopening), c("meanNetopening") :=
           mean(Netopening)]
spain[!is.na(DoorSpread), c("meanDoorSpread"):=
        mean(DoorSpread)]
spain[!is.na(Depth), c("DepthCenter") :=
           Depth-meanDepth]
spain[!is.na(Depth), c("LogDepthCenter") :=
           log(Depth)-log(meanDepth)]
spain[!is.na(WingSpread), c("WingSpreadCenter") :=
           WingSpread-meanWingSpread]
spain[!is.na(DoorSpread), c("DoorSpreadCenter") :=
        DoorSpread-meanDoorSpread]
spain[!is.na(WingSpread), c("LogWingSpreadCenter") :=
           log(WingSpread)-log(meanWingSpread)]
spain[!is.na(DoorSpread), c("LogDoorSpreadCenter") :=
        log(DoorSpread)-log(meanDoorSpread)]
spain[!is.na(Netopening), c("NetopeningCenter") :=
           Netopening-meanNetopening]
spain[!is.na(Netopening), c("LogNetopeningCenter") :=
           log(Netopening)-log(meanNetopening)]
spain$SweepCat<-as.factor(spain$SweepLngt)
summary(as.factor(spain$Ship))

#######################
# WingSpread BAK/PORC #
#######################
# Model Wing Data
######################
plot(spain$WingSpread, spain$DoorSpread, pch=19, col=cols[as.factor(spain$Gear)])
plot(spain$DepthNew, spain$WingSpread, pch=19,col=cols[as.factor(spain$Gear)])
# set up data set for model selection
alldat<-spain[!is.na(spain$DoorSpread) & !is.na(spain$WingSpread)
              & !is.na(spain$Netopening), ]
# 80 observations in dataset.
door_dat<-spain[!is.na(spain$DoorSpread),]
wing_dat<-spain[is.na(spain$WingSpread),]
summary(wing_dat$DoorSpread)

fm<-lmer(log(WingSpread) ~ LogDoorSpreadCenter
         + LogDepthCenter
         + LogNetopeningCenter
         + SweepCat + Gear
         + (1|Ship:StatRec:Year:Quarter:DoorType) , 
      # Variance added by (1|Ship:StatRec:Year:Quarter:DoorType) 
      # is 0.0006339 with a SD of 0.02518 this is rather small I will remove a term
         data=alldat, REML=F)
summary(fm)
fm1<-lmer(log(WingSpread) ~ LogDoorSpreadCenter
         + LogDepthCenter
         + LogNetopeningCenter
         + SweepCat+Gear
          + (1|Ship:StatRec:Quarter:DoorType) , 
         # Variance added by (1|Ship:StatRec:Quarter:DoorType) 
         # is 0.000000 with a SD of 0.0000 remove term
         data=alldat, REML=F)
summary(fm1)
fm2<-lm(log(WingSpread) ~ LogDoorSpreadCenter
          + LogDepthCenter
          + LogNetopeningCenter
          + SweepCat+Gear,
          data=alldat)
summary(fm2)
# netopening isn't significant nor is depth - I'll remove net opening first as that
# data isn't alway available
fm3<-lm(log(WingSpread) ~ LogDoorSpreadCenter
        + LogDepthCenter
        + SweepCat+Gear,
        data=alldat)
summary(fm3)
fm4<-lm(log(WingSpread) ~ LogDoorSpreadCenter
       # + LogDepthCenter
        + SweepCat+Gear,
        data=alldat)
summary(fm5)
fm5<-lm(log(WingSpread) ~ LogDoorSpreadCenter:SweepCat:Gear,data=alldat)
fm6<-lm(log(WingSpread) ~ LogDoorSpreadCenter:SweepCat,data=alldat)
anova(fm5, fm6)
AIC(fm5, fm6)

predict<-exp(predict(fm6))
col1<-c( "darkred","darkgreen")
points(alldat$DepthNew, predict, col=col1[as.factor(alldat$Gear)], pch=19)

# fm5 is top choice but what happens if Doorspread isn't recorded?
fm1<-lm(log(WingSpread) ~ LogDepthCenter:LogNetopeningCenter:SweepCat:Gear,
        data=alldat)
fm2<-lm(log(WingSpread) ~ LogDepthCenter:SweepCat:Gear,
        data=alldat)
        #+ LogNetopeningCenter
AIC(fm1, fm2)
summary(fm1)
qqnorm(residuals((fm2)))
qqline(residuals(fm2), col="red")
predictfm<-exp(predict(fm2))
plot(spain$DepthNew, spain$WingSpread, pch=19,col=cols[as.factor(spain$Gear)],
     ylab="Wing Spread(m)", xlab="Depth (m)")

points(alldat$DepthNew, predictfm, pch=19, col=col1[as.factor(alldat$Gear)]) 
lines(stats::lowess(alldat$DepthNew, predictfm), col='black')
#####################################
# Predict Wing Spread Results Spain #
#####################################
# first I need all the centered and logged data for hauls
######
str(hauls)
#Get Means
hauls$meanDepth<-mean(hauls$DepthNew)
hauls$meanWingSpread[!is.na(hauls$WingSpread)]<-13.79
hauls$meanNetopening[!is.na(hauls$Netopening)]<-4.349
hauls$meanDoorSpread[!is.na(hauls$DoorSpread)]<-59.8
# Get Centered data
hauls$DepthCenter<-hauls$DepthNew-hauls$meanDepth
hauls$WingSpreadCenter<-hauls$WingSpread-hauls$meanWingSpread
hauls$DoorSpreadCenter<-hauls$DoorSpread-hauls$meanDoorSpread
hauls$LogDoorSpreadCenter<-hauls$Netopening-hauls$meanNetopening
# Log and Center the Data
hauls$LogDepthCenter<-log(hauls$DepthNew)-log(hauls$meanDepth)
hauls$LogWingSpreadCenter<-log(hauls$WingSpread)-log(hauls$meanWingSpread)
hauls$LogDoorSpreadCenter<-log(hauls$DoorSpread)-log(hauls$meanDoorSpread)
hauls$LogNetopeningCenter<-log(hauls$Netopening)-log(hauls$meanNetopening)
hauls$SweepCat<-as.factor(hauls$SweepLngt)
summary(as.factor(hauls$Ship))
######
# chosen models fm6 and fm2
# model1: fm6<-lm(log(WingSpread) ~ LogDoorSpreadCenter:SweepCat,data=alldat)

wing_dat<-subset(hauls, Country=="SPA"& !is.na(DoorSpread),)
model1<-lm(log(WingSpread) ~ LogDoorSpreadCenter:SweepCat,
           data=wing_dat)
summary(model1)
wing_dat_len <- nrow(wing_dat)
wing_dat$predict_lm_wing_dat<-exp(predict(model1, wing_dat, allow.new.levels=T))
plot(wing_dat$DepthNew,exp(wing_dat$predict_lm_wing_dat),
     pch=19, col=cols[as.factor(wing_dat$Gear)])
# model2: fm2<-lm(log(WingSpread) ~ LogDepthCenter:SweepCat:Gear,data=alldat)
wing_dat2<-subset(hauls, Country=="SPA",)
model2<-lm(log(WingSpread) ~ LogDepthCenter:SweepCat,data=wing_dat2)

summary(model2)
wing_dat_len <- nrow(wing_dat2)
wing_dat2$predict_lm_wing_dat<-exp(predict(model2, wing_dat2, allow.new.levels=T))
summary(wing_dat2$predict_lm_wing_dat)
plot(wing_dat2$DepthNew,exp(wing_dat2$predict_lm_wing_dat),
     pch=19, col=cols[as.factor(wing_dat2$Gear)])
list<-wing_dat2$UniqueID

# predict results for spains wing spread data
hauls$Use_WingSpread[!is.na(hauls$WingSpread)&hauls$Country=="SPA"]<-hauls$WingSpread[!is.na(hauls$WingSpread)&hauls$Country=="SPA"]
hauls$QualityWing[!is.na(hauls$WingSpread)&hauls$Country=="SPA"]<-"raw_wingspread"

list<-wing_dat$UniqueID
hauls$mod1_wingspread_spa[hauls$UniqueID%in%list]<-wing_dat$predict_lm_wing_dat[wing_dat$UniqueID%in%list]
list<-wing_dat2$UniqueID
hauls$mod2_wingspread_spa[hauls$Country=="SPA"]<-wing_dat2$predict_lm_wing_dat[wing_dat$UniqueID%in%list]

hauls$Use_WingSpread[is.na(hauls$WingSpread)&hauls$Country=="SPA"]<-hauls$mod1_wingspread_spa[is.na(hauls$WingSpread)&hauls$Country=="SPA"]
hauls$QualityWing[is.na(hauls$WingSpread)&!is.na(hauls$mod1_wingspread_spa)&
                    hauls$Country=="SPA"]<-"mod1_wingspread_spa"

hauls$Use_WingSpread[is.na(hauls$Use_WingSpread)&
                       hauls$Country=="SPA"]<-hauls$mod2_wingspread_spa[is.na(hauls$Use_WingSpread)&hauls$Country=="SPA"]
hauls$QualityWing[is.na(hauls$Use_WingSpread)&is.na(hauls$mod1_wingspread_spa)&
                          hauls$Country=="SPA"]<-"mod2_wingspread_spa"
hauls$QualityWing[is.na(hauls$QualityWing)&
                    hauls$Country=="SPA"]<-"mod2_wingspread_spa"
summary(hauls$Use_WingSpread[hauls$Country=="SPA"])

png(file="WingSpread_data_spain_col_27-05-2016.png", bg="transparent")
plot(hauls$DepthNew[hauls$Country=="SPA"], hauls$Use_WingSpread[hauls$Country=="SPA"],
    col=cols[as.factor(hauls$QualityWing[hauls$Country=="SPA"])], pch=19,
    xlab="Depth (m)", ylab="WingSpread (m)")
legend(5, 35, levels(as.factor(hauls$QualityWing[hauls$Country=="SPA"])), 
       col=cols, 
       pch=15, ncol=1, cex=1, bty="n")
dev.off()
#############
# lets clear the workspace again
rm(alldat, corhaul, corrhaul_rot, door_dat, ds, fm, fm1, fm2, fm3, fm4, fm5, fm6,
   gs1, gs2, gs3, gsDat, list, no_dat, predict, predictfm, test, wing_dat, 
   wing_dat2, wing_dat_len, ws, ws_dat)
#######################
# DoorSpread BAK/PORC #
#######################
###############################
dm1<-lm(log(DoorSpread) ~ LogWingSpreadCenter:SweepCat:Gear+
          LogDepthCenter:SweepCat:Gear+
          LogNetopeningCenter:SweepCat:Gear,
              data=spain)
dm2<-lm(log(DoorSpread) ~ LogWingSpreadCenter:SweepCat:Gear+
          LogDepthCenter:SweepCat:Gear,
        data=spain)
dm3<-lm(log(DoorSpread) ~ LogWingSpreadCenter:SweepCat:Gear,
        data=spain)
summary(dm3)
dm4<-lm(log(DoorSpread) ~ 
          LogDepthCenter:SweepCat:Gear,
        data=spain)
summary(dm4)

# 2 models selected - model 3 and model 4
# model3: dm3<-lm(log(DoorSpread) ~ LogWingSpreadCenter:SweepCat:Gear,data=spain)

door_dat<-subset(hauls, Country=="SPA"& !is.na(WingSpread),)
dm3<-lm(log(DoorSpread) ~ LogWingSpreadCenter:SweepCat:Gear,data=door_dat)
summary(dm3)
door_dat_len <- nrow(door_dat)
door_dat$predict_lm_door_dat<-exp(predict(dm1, door_dat, allow.new.levels=T))
plot(door_dat$DepthNew,(door_dat$predict_lm_door_dat),
     pch=19, col=cols[as.factor(door_dat$Gear)])
# model2: dm4<-lm(log(DoorSpread) ~ LogDepthCenter:SweepCat:Gear,data=spain)
door_dat2<-subset(hauls, Country=="SPA",)
dm4<-lm(log(DoorSpread) ~ LogDepthCenter:SweepCat:Gear, data=door_dat2)
summary(dm4)
door_dat_len <- nrow(door_dat2)
door_dat2$predict_lm_door_dat<-exp(predict(dm4, door_dat2, allow.new.levels=T))
summary(door_dat2$predict_lm_door_dat)
plot(door_dat2$DepthNew,(door_dat2$predict_lm_door_dat),
     pch=19, col=cols[as.factor(door_dat2$Gear)])
# predict results for spains door spread data
hauls$Use_DoorSpread<-hauls$DoorSpread
hauls$QualityDoor[!is.na(hauls$DoorSpread)]<-"raw_doorspread"

list<-door_dat$UniqueID
hauls$mod1_doorspread_spa[hauls$UniqueID%in%list]<-door_dat$predict_lm_door_dat[door_dat$UniqueID%in%list]
list<-door_dat2$UniqueID
hauls$mod2_doorspread_spa[hauls$Country=="SPA"]<-door_dat2$predict_lm_door_dat[door_dat$UniqueID%in%list]

hauls$Use_DoorSpread[is.na(hauls$DoorSpread)&
                       hauls$Country=="SPA"]<-hauls$mod1_doorspread_spa[is.na(hauls$DoorSpread)&
                                                                          hauls$Country=="SPA"]
hauls$QualityDoor[is.na(hauls$DoorSpread)&!is.na(hauls$mod1_doorspread_spa)]<-"mod1_wingspread_spa"

hauls$Use_DoorSpread[is.na(hauls$Use_DoorSpread)&
                       hauls$Country=="SPA"]<-hauls$mod2_doorspread_spa[is.na(hauls$Use_DoorSpread)&hauls$Country=="SPA"]
hauls$QualityDoor[is.na(hauls$DoorSpread)&is.na(hauls$mod1_doorspread_spa)&
                    hauls$Country=="SPA"]<-"mod2_wingspread_spa"

summary(hauls$Use_DoorSpread[hauls$Country=="SPA"])

png(file="DoorSpread_data_spain_col.png", bg="transparent")
plot(hauls$DepthNew[hauls$Country=="SPA"], hauls$Use_DoorSpread[hauls$Country=="SPA"],
     col=cols[as.factor(hauls$QualityDoor[hauls$Country=="SPA"])], pch=19,
     xlab="Depth (m)", ylab="DoorSpread (m)")
legend(400, 75, levels(as.factor(hauls$QualityDoor[hauls$Country=="SPA"])), 
       col=cols, 
       pch=15, ncol=1, cex=1, bty="n")
dev.off()
#######################
# Netopening BAK/PORC #
#######################
################################################################

# only 6 obs with both wing and door but no net - not worth including both in mod.
# door with no net 43 obs and wing 148 obs - less than 5% of the data needing estimated

nm1<-lm(log(Netopening) ~ LogDepthCenter:SweepCat:Gear:Quarter,
          data=spain)
summary(nm1)
nm2<-lm(log(Netopening) ~ LogDepthCenter:SweepCat:Gear,
        data=spain)
summary(nm2)
nm3<-lm(log(Netopening) ~ LogDepthCenter:SweepCat,
        data=spain)
summary(nm3)
# gear not adding much

# use model 3 it explains about 21 % of variation - poor in comparsion to Wing
# and Door but better than using a straight mean.
nm3<-lm(log(Netopening) ~ LogDepthCenter:SweepCat, data=spain)
summary(nm3)
spain_len <- nrow(spain)
spain$predict_lm_net_dat<-exp(predict(nm1, spain, allow.new.levels=T))
plot(spain$DepthNew,(spain$predict_lm_net_dat),
     pch=19, col=cols[as.factor(spain$Gear)])
# predict results for spains net opening data
hauls$Use_Netopening[!is.na(hauls$Netopening)&
                       hauls$Country=="SPA"]<-hauls$Netopening[!is.na(hauls$Netopening)&
                                                                 hauls$Country=="SPA"]
hauls$QualityNet[!is.na(hauls$Netopening)]<-"raw_netopening"

list<-spain$UniqueID
hauls$mod1_netopening_spa[hauls$UniqueID%in%list]<-spain$predict_lm_net_dat[spain$UniqueID%in%list]

hauls$Use_Netopening[is.na(hauls$Netopening)&
                       hauls$Country=="SPA"]<-hauls$mod1_netopening_spa[is.na(hauls$Netopening)&
                                                                          hauls$Country=="SPA"]
hauls$QualityNet[is.na(hauls$Netopening)&!is.na(hauls$mod1_netopening_spa)]<-"mod1_net_spa"

summary(hauls$Use_Netopening[hauls$Country=="SPA"])
summary(as.factor(hauls$QualityNet[hauls$Country=="SPA"]))
png(file="NetOpening_data_spain_col.png", bg="transparent")
plot(hauls$DepthNew[hauls$Country=="SPA"], hauls$Use_Netopening[hauls$Country=="SPA"],
     col=cols[as.factor(hauls$QualityNet[hauls$Country=="SPA"])], pch=19,
     xlab="Depth (m)", ylab="Net Opening (m)")
legend(0, 4, levels(as.factor(hauls$QualityNet[hauls$Country=="SPA"])), 
       col=cols, 
       pch=15, ncol=1, cex=1, bty="n")
dev.off()
summary(hauls$Use_Netopening[hauls$Country=="SPA"])
########################################
# lets clear the workspace again before we start on the GOV stuff!
rm(spain_len, spain, numCols, nm3, nm2, nm1, net, model1, model2, list, 
   door_dat2, door_dat_len, door_dat, dm4, dm3, dm2, dm1, coeff, coeffs)

summary(hauls$Use_WingSpread[!hauls$Gear=="GOV"])
summary(as.factor(hauls$QualityWing[!hauls$Gear=="GOV"]))
# so at this point some of the results haven't transfered over - code reviewed
# and changes made
write.csv(hauls, "hauls_monster_file27-05-2016.csv")
##################
# WingSpread GOV #
##################
#Centered data for model
str(hauls)

# Add Sweep Cats - See Est Sweep Cats above.
hauls[!is.na(Year), "Yearfac":=
        as.factor(Year)]
hauls[!is.na(Quarter), "Qfac":=
        as.factor(Quarter)]
hauls[!is.na(Ship), "Shipfac":=
        as.factor(Ship)]
summary(as.factor(hauls$EstSweepCat[hauls$Gear=="GOV"]))
# for model election set up training data set
train<-subset(hauls, Gear=="GOV"& (!is.na(WingSpread)) & (!is.na(DoorSpread))
              &(!is.na(Netopening)),)
# Linear Mixed model with random effects reviewed after comments from V.T at IBTS
lm1 <- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat
            + LogNetopeningCenter:EstSweepCat
            + LogDoorSpreadCenter:EstSweepCat
            + (LogDepthCenter:LogNetopeningCenter:LogDoorSpreadCenter|Ship) 
            + (1|Ship:EstSweepCat) # scalar random effects
            + (1|Ship:Yearfac:Qfac:StatRec), # additative random effect for each ship
            # captures all the random, temporal and
            # spatial noise
            data=train, REML=FALSE)
summary(lm1)
r.squaredGLMM(lm1)
lm2 <- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat
            + LogNetopeningCenter:EstSweepCat
            + LogDoorSpreadCenter:EstSweepCat
            + (LogDepthCenter:LogNetopeningCenter:LogDoorSpreadCenter|Ship) 
            + (1|Ship:EstSweepCat) # scalar random effects
            + (1|Ship:Qfac:StatRec), # additative random effect for each ship
            # captures all the random, temporal and
            # spatial noise
            data=train, REML=FALSE)
summary(lm2)
lm3<- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat:Ship
            + LogNetopeningCenter:EstSweepCat:Ship
            + LogDoorSpreadCenter:EstSweepCat:Ship
            + (LogDepthCenter:LogNetopeningCenter:LogDoorSpreadCenter|Ship) 
            + (1|Ship:EstSweepCat) # scalar random effects
            + (1|Ship:Qfac:StatRec), # additative random effect for each ship
            # captures all the random, temporal and
            # spatial noise
            data=train, REML=FALSE)
summary(lm3)
lm4<- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat:Ship
           #+ LogNetopeningCenter:EstSweepCat:Ship
           + LogDoorSpreadCenter:EstSweepCat:Ship
           + (LogDepthCenter:LogNetopeningCenter:LogDoorSpreadCenter|Ship) 
           + (1|Ship:EstSweepCat) # scalar random effects
           + (1|Ship:Qfac:StatRec), # additative random effect for each ship
           # captures all the random, temporal and
           # spatial noise
           data=train, REML=FALSE)
summary(lm4)
lm5<- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat:Ship
           #+ LogNetopeningCenter:EstSweepCat:Ship
         #  + LogDoorSpreadCenter:EstSweepCat:Ship
           + (LogDepthCenter:LogNetopeningCenter:LogDoorSpreadCenter|Ship) 
           + (1|Ship:EstSweepCat) # scalar random effects
           + (1|Ship:Qfac:StatRec), # additative random effect for each ship
           # captures all the random, temporal and
           # spatial noise
           data=train, REML=FALSE)
lm6<- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat:Ship
           #+ LogNetopeningCenter:EstSweepCat:Ship
           #  + LogDoorSpreadCenter:EstSweepCat:Ship
          # + (LogDepthCenter:LogNetopeningCenter:LogDoorSpreadCenter|Ship) 
           + (1|Ship:EstSweepCat) # scalar random effects
           + (1|Ship:Qfac:StatRec), # additative random effect for each ship
           # captures all the random, temporal and
           # spatial noise
           data=train, REML=FALSE)
lm7<- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat:Ship
              + (1|Ship:Qfac:StatRec), # additative random effect for each ship
           # captures all the random, temporal and
           # spatial noise
           data=train, REML=FALSE)
# lm8<- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat:Ship
#           + (Ship|Qfac:StatRec), # additative random effect for each ship
           # captures all the random, temporal and
           # spatial noise
#           data=train, REML=FALSE) # model can't converge
summary(lm5)
r.squaredGLMM(lm1)
r.squaredGLMM(lm2)
r.squaredGLMM(lm3)
r.squaredGLMM(lm4)
r.squaredGLMM(lm5)
r.squaredGLMM(lm6)
r.squaredGLMM(lm7)
# r.squaredGLMM(lm8) # Way too computationally intensive 

cols<-rainbow(6)
data<-predict(lm7)
summary(as.factor(train$Survey))
png(file="GOV_Wingspreads_model2_27-05-2016.png", bg="transparent")
plot(train$DepthNew, train$WingSpread, col=cols[as.factor(train$Survey)], 
     pch=15, xlab="Depth (m)", ylab="WingSpread(m)")
points(train$DepthNew, exp(data), pch=21, col=cols[as.factor(train$Survey)],
     bg="black")
lines(lowess(train$WingSpread~train$DepthNew), col="black", lwd=2)
lines(lowess(exp(data)~train$DepthNew), col="red", lwd=3, lty=2)
legend(600, 40, levels(as.factor(hauls$Survey[hauls$Gear=="GOV"])), 
       col=cols, 
       pch=15, ncol=1, cex=1, bty="n")
dev.off()
png(file="GOV_Wingspreads_model1_27-05-2016.png", bg="transparent")
data_best<-predict(lm3)
plot(train$DepthNew, train$WingSpread, col=cols[as.factor(train$Survey)], 
     pch=15, xlab="Depth (m)", ylab="WingSpread(m)")
points(train$DepthNew, exp(data_best), pch=21, col=cols[as.factor(train$Survey)],
       bg="black")
lines(lowess(train$WingSpread~train$DepthNew), col="black", lwd=2)
lines(lowess(exp(data_best)~train$DepthNew), col="red", lwd=3, lty=2)
legend(600, 40, levels(as.factor(hauls$Survey[hauls$Gear=="GOV"])), 
       col=cols, 
       pch=15, ncol=1, cex=1, bty="n")
dev.off()
##################
# note - less compex model below can't explain as much variance as mixed model
# lm8<- lm(log(WingSpread) ~ LogDepthCenter:EstSweepCat:Ship:Qfac,
#            data=train)
# summary(lm8)

# anova(lm1, lm2, lm3, lm4, lm5, lm6)
# dotplot(ranef(lm1, postVR=TRUE))
# qqmath(ranef(lm1, postVR=TRUE))
# qqmath(ranef(lm2, postVR=TRUE))
# qqmath(ranef(lm3, postVR=TRUE))
# qqmath(ranef(lm4, postVR=TRUE))
# qqmath(ranef(lm5, postVR=TRUE))
# qqmath(ranef(lm6, postVR=TRUE))
# qqmath(ranef(lm7, postVR=TRUE))
###############################################################
#ggplot(data = train, aes(x=Depth, y=WingSpread, col=Survey)) +
#  geom_point(aes(shape=Survey)) +
#  scale_colour_manual(values=c("black","red", "lightgrey", "darkgrey", "blue")) +
#  geom_smooth(span=2, aes(group=1))+ 
#  theme(legend.position=c(0.2,0.9)) + 
#  ggtitle("")+
#  theme_classic()

# plot(train$Depth, train$WingSpread, pch=19, col="black", xlab="Depth (m)", 
#     ylab="Wing Spread (m)")
# lowess<-predict(loess(WingSpread ~ Depth , data=train), se=T)
# lm6dat<-predict(lm6)
# points(train$Depth,exp(lm6dat), pch=1, col="lightgrey")

#rough & ready CI by adding and subtracting 2 times the standard error to the mean
# lines(train$Depth,loessws$fit+2*plx$s, lty=2) 
# lines(train$Depth,loessws$fit-2*plx$s, lty=2)
########################################
# set up user data using selected 2 models
# subset all GOV gear
hauls$EstSweepCat<-as.factor(hauls$EstSweepCat)
hauls$Ship<-as.factor(hauls$Ship)
the_gov<-subset(hauls, Gear=="GOV")
summary(the_gov$WingSpread)
summary(the_gov$LogDoorSpreadCenter)
str(the_gov)
# 30538 obs

summary(the_gov$EstSweepCat)
lm3a<- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat
           + LogNetopeningCenter:EstSweepCat
           + LogDoorSpreadCenter:EstSweepCat
           + (LogDepthCenter:LogNetopeningCenter:LogDoorSpreadCenter|Ship) 
           + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
           data=the_gov, REML=FALSE)
summary(lm3a)
r.squaredGLMM(lm3a)
need_wings_have_all<-subset(hauls, Gear=="GOV"& is.na(WingSpread) & !is.na(DoorSpread)
                            &!is.na(Netopening),)
need_wings_have_all_len<-nrow(need_wings_have_all)
#7206
need_wings_have_all$mod1_wingspread_gov<-exp(predict(lm3a, need_wings_have_all, allow.new.levels=T))
need_wings<-subset(hauls, Gear=="GOV"& (is.na(WingSpread)))
summary(lm3)
r.squaredGLMM(lm3a)
need_wings_have_all<-subset(hauls, Gear=="GOV"& is.na(WingSpread) & !is.na(DoorSpread)
                            &!is.na(Netopening),)
need_wings_have_all_len<-nrow(need_wings_have_all)
#7206
need_wings_have_all$mod1_wingspread_gov<-exp(predict(lm3a, need_wings_have_all, allow.new.levels=T))

# 18386

7206/18386

lm7a<- lmer(log(WingSpread) ~ LogDepthCenter:EstSweepCat
           + (1|Ship:Qfac:StatRec),  data=the_gov, REML=FALSE)
summary(lm7a)
r.squaredGLMM(lm7a)
need_wings<-subset(hauls, Gear=="GOV"& is.na(WingSpread),)
need_wings_len<-nrow(need_wings)
#7206
need_wings$mod2_wingspread_gov<-exp(predict(lm7a, need_wings, allow.new.levels=T))
summary(need_wings$mod2_wingspread_gov)
###############################
# If real values are available use these
# predict results for spains net opening data
hauls$Use_WingSpread[!is.na(hauls$WingSpread)&
                       hauls$Gear=="GOV"]<-hauls$WingSpread[!is.na(hauls$WingSpread)&
                                                              hauls$Gear=="GOV"]
hauls$QualityWing[!is.na(hauls$WingSpread)]<-"raw_wingspread"

list<-need_wings_have_all$UniqueID
hauls$mod1_wingspread_gov[hauls$UniqueID%in%list]<-need_wings_have_all$mod1_wingspread_gov[need_wings_have_all$UniqueID%in%list]

hauls$Use_WingSpread[is.na(hauls$WingSpread)&
                       hauls$Gear=="GOV"]<-hauls$mod1_wingspread_gov[is.na(hauls$WingSpread)&
                                                                          hauls$Gear=="GOV"]
hauls$QualityWing[is.na(hauls$WingSpread)&!is.na(hauls$mod1_wingspread_gov)&
                    hauls$Gear=="GOV"]<-"mod1_wing_gov"
# model 2 next
list<-need_wings$UniqueID
hauls$mod2_wingspread_gov[hauls$UniqueID%in%list]<-need_wings$mod2_wingspread_gov[need_wings$UniqueID%in%list]

hauls$Use_WingSpread[is.na(hauls$Use_WingSpread)&
                       hauls$Gear=="GOV"]<-hauls$mod2_wingspread_gov[is.na(hauls$Use_WingSpread)&
                                                                       hauls$Gear=="GOV"]
hauls$QualityWing[is.na(hauls$WingSpread)&is.na(hauls$mod1_wingspread_gov)&
                    hauls$Gear=="GOV"]<-"mod2_wing_gov"

#check wing speads 
summary((hauls$Use_WingSpread[hauls$Gear=="GOV"]))
summary(hauls$Use_WingSpread)
# clear r environment again
rm(curWarnings, data, data_best, getDATRAS, list, lm1, lm2, lm3,lm4,lm5,lm6,
   lm7,lm8, need_wings_len,need_wings, need_wings_have_all_len, need_wings_have_all,
   train)
##################
# DoorSpread GOV #
##################
# for model election set up training data set
train<-subset(hauls, Gear=="GOV"& (!is.na(WingSpread)) & (!is.na(DoorSpread))
              &(!is.na(Netopening)),)
# Linear Mixed model with random effects reviewed after comments from V.T at IBTS
lm1 <- lmer(log(DoorSpread) ~ LogDepthCenter:EstSweepCat
            + LogNetopeningCenter:EstSweepCat
            + LogWingSpreadCenter:EstSweepCat
            + (LogDepthCenter:LogNetopeningCenter:LogWingSpreadCenter|Ship) 
            + (1|Ship:EstSweepCat) # scalar random effects
            + (1|Ship:Yearfac:Qfac:StatRec), # additative random effect for each ship
            # captures all the random, temporal and
            # spatial noise
            data=train, REML=FALSE)
# Address Warning message:
#  In checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#                 Model is nearly unidentifiable: large eigenvalue ratio
#               - Rescale variables?
# Rescale and center continuous parameters # already using scaled variables
summary(lm1)
r.squaredGLMM(lm1)
# Check singularity
tt<-getME(lm1, "theta")
ll<-getME(lm1, "lower")
min(tt[ll==0])
# The definition of singularity is that some of the constrained parameters 
# of the random effects theta parameters are on the boundary (equal to zero, 
# or very very close to zero, say <106<106):
## [1] 0.02440647 # not a problem here

#Double-checking gradient calculations
# Extract pre-computed information:
  
  derivs1 <- lm1@optinfo$derivs
sc_grad1 <- with(derivs1,solve(Hessian,gradient))
max(abs(sc_grad1))
# [1] 0.01817998
# One general problem is that large scaled gradients are often associated 
# with small absolute gradients: we might decide that were more interested
# in testing the (parallel) minimum of these two quantities:
  
  max(pmin(abs(sc_grad1),abs(derivs1$gradient)))
# 1.771696e-05
# This is a lot smaller, and below the typically set tolerance (0.001).
  # tweak model for better convergence
lm2 <- lmer(log(DoorSpread) ~ LogDepthCenter:EstSweepCat
            + LogNetopeningCenter:EstSweepCat
            + LogWingSpreadCenter:EstSweepCat
            + (LogDepthCenter:LogNetopeningCenter:LogWingSpreadCenter|Ship) 
            + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
            data=train, REML=FALSE)
summary(lm2)
lm3<- lmer(log(DoorSpread) ~ LogDepthCenter:EstSweepCat:Ship
           + (LogDepthCenter:LogNetopeningCenter:LogWingSpreadCenter|Ship) 
           + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
           data=train, REML=FALSE)
summary(lm3)
r.squaredGLMM(lm3)
lm4<- lmer(log(DoorSpread) ~ LogDepthCenter:EstSweepCat
           + (LogDepthCenter:LogNetopeningCenter:LogWingSpreadCenter|Ship) 
           + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
           data=train, REML=FALSE)
summary(lm4)
r.squaredGLMM(lm4)

lm5<- lmer(log(DoorSpread) ~ LogDepthCenter:EstSweepCat
           + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
            data=train, REML=FALSE)
summary(lm5)
r.squaredGLMM(lm5)

#lm6<- lmer(log(DoorSpread) ~ LogDepthCenter:EstSweepCat:Ship
#           + (1|Ship:EstSweepCat), 
#         data=train, REML=FALSE)
summary(lm6)
r.squaredGLMM(lm6)
lm7<- lmer(log(DoorSpread) ~ LogDepthCenter:EstSweepCat
           + (1|Ship:EstSweepCat), 
           data=train, REML=FALSE)

summary(lm7)
r.squaredGLMM(lm7)
#alt_mod<- lm(log(DoorSpread) ~ LogDepthCenter:EstSweepCat:Ship, data=train)
#summary(alt_mod)
#AIC(lm1,lm2,lm3, lm4, lm5,lm6,lm7)

#r.squaredGLMM(lm1)
#r.squaredGLMM(lm2)
#r.squaredGLMM(lm3)
#r.squaredGLMM(lm4)
#r.squaredGLMM(lm5)
#r.squaredGLMM(lm6)
#r.squaredGLMM(lm7)

cols<-rainbow(6)
data<-predict(lm5)
summary(as.factor(train$Survey))
png(file="GOV_Doorspreads_model1.png", bg="transparent")
plot(train$DepthNew, train$DoorSpread, col=cols[as.factor(train$Survey)], 
     pch=15, xlab="Depth (m)", ylab="WingSpread(m)")
points(train$DepthNew, exp(data), pch=21, col=cols[as.factor(train$Survey)],
       bg="black")
lines(lowess(train$DoorSpread~train$DepthNew), col="black", lwd=2)
lines(lowess(exp(data)~train$DepthNew), col="lightgrey", lwd=3, lty=2)
legend(600, 100, levels(as.factor(hauls$Survey[hauls$Gear=="GOV"])), 
       col=cols, pch=15, ncol=1, cex=1, bty="n")
dev.off()

##################
# note - less compex model can't explain as much variance as mixed model
# the random effects are accounting for quite a lot of variance

# set up user data using selected model
# subset all GOV gear
the_gov<-subset(hauls, Gear=="GOV")
# 30538 obs
door_mod<- lmer(log(DoorSpread) ~ LogDepthCenter:EstSweepCat
           + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
           data=the_gov, REML=FALSE)
summary(lm5)
r.squaredGLMM(lm5)

the_gov$mod1_doorspread_gov<-exp(predict(lm5, the_gov, allow.new.levels=T))

summary(the_gov$mod1_doorspread_gov)

###############################
# If real values are available use these
# predict results for spains net opening data
hauls$Use_DoorSpread[!is.na(hauls$DoorSpread)&
                       hauls$Gear=="GOV"]<-hauls$DoorSpread[!is.na(hauls$DoorSpread)&
                                                              hauls$Gear=="GOV"]
hauls$QualityDoor[!is.na(hauls$DoorSpread)]<-"raw_doorspread"

list<-the_gov$UniqueID
hauls$mod1_doorspread_gov[hauls$UniqueID%in%list]<-the_gov$mod1_doorspread_gov[the_gov$UniqueID%in%list]

hauls$Use_DoorSpread[is.na(hauls$DoorSpread)&
                       hauls$Gear=="GOV"]<-hauls$mod1_doorspread_gov[is.na(hauls$DoorSpread)&
                                                                       hauls$Gear=="GOV"]
hauls$QualityDoor[is.na(hauls$DoorSpread)&!is.na(hauls$mod1_doorspread_gov)&
                    hauls$Gear=="GOV"]<-"mod1_door_gov"

#check door spreads
summary((hauls$Use_DoorSpread[hauls$Gear=="GOV"]))
summary(as.factor(hauls$QualityDoor[hauls$Gear=="GOV"]))

summary((hauls$Use_DoorSpread))
summary(as.factor(hauls$QualityDoor))

summary((hauls$Use_WingSpread))
summary(as.factor(hauls$QualityWing))

# again lets do some cleaning
rm(tt, sc_grad1, lm1, lm2, lm3, lm4,lm6,lm7,data,
   data_best, derivs1)
###################
# Net Opening GOV #
###################
# for model selection set up training data set
# train<-subset(hauls, Gear=="GOV"& (!is.na(WingSpread)) & (!is.na(DoorSpread))
#              &(!is.na(Netopening)),)
# and for data prediction use the_gov data set
# Linear Mixed model with random effects reviewed after comments from V.T at IBTS
lm1 <- lmer(log(Netopening) ~ LogDepthCenter:EstSweepCat
            + LogDoorSpreadCenter:EstSweepCat
            + LogWingSpreadCenter:EstSweepCat
            + (LogDepthCenter:LogDoorSpreadCenter:LogWingSpreadCenter|Ship) 
            + (1|Ship:EstSweepCat) 
            + (1|Ship:Yearfac:Qfac:StatRec), 
             data=train, REML=FALSE)
summary(lm1)
r.squaredGLMM(lm1)

# so the random effect of Ship:SweepCat doesnt add much (~0.003) 
lm2 <- lmer(log(Netopening) ~ LogDepthCenter:EstSweepCat
           + (LogDepthCenter:LogDoorSpreadCenter:LogWingSpreadCenter|Ship) 
            + (1|Ship:EstSweepCat)  + (1|Ship:Qfac:StatRec), 
            data=train, REML=FALSE)
summary(lm2)
r.squaredGLMM(lm2)
lm3<- lmer(log(Netopening) ~ LogDepthCenter:EstSweepCat:Ship
           + LogWingSpreadCenter:Ship 
           + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
           data=train, REML=FALSE)
plot(train$DepthNew,train$Netopening )
plot(train$WingSpread,train$Netopening )
summary(lm3)
r.squaredGLMM(lm3)

lm4<- lmer(log(Netopening) ~ LogDepthCenter:EstSweepCat:Ship
           + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
           data=train, REML=FALSE)
summary(lm4)
r.squaredGLMM(lm4)

lm5<- lmer(log(Netopening) ~ LogDepthCenter:EstSweepCat
           + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
           data=train, REML=FALSE)
summary(lm5)
AIC(lm1, lm2,lm3,lm4,lm5)
r.squaredGLMM(lm3)
r.squaredGLMM(lm5)
# use model lm5

cols<-rainbow(6)
data<-predict(lm5)
summary(as.factor(train$Survey))
png(file="GOV_Netopening_model1.png", bg="transparent")
plot(train$DepthNew, train$Netopening, col=cols[as.factor(train$Survey)], 
     pch=15, xlab="Depth (m)", ylab="Netopening(m)")
points(train$DepthNew, exp(data), pch=21, col=cols[as.factor(train$Survey)],
       bg="black")
lines(lowess(train$Netopening~train$DepthNew), col="black", lwd=2)
lines(lowess(exp(data)~train$DepthNew), col="lightgrey", lwd=3, lty=2)
legend(600, 9, levels(as.factor(hauls$Survey[hauls$Gear=="GOV"])), 
       col=cols, pch=15, ncol=1, cex=1, bty="n")
dev.off()

##################
# note - less compex model can't explain as much variance as mixed model
# the random effects are accounting for quite a lot of variance

# set up user data using selected model
# subset all GOV gear
the_gov<-subset(hauls, Gear=="GOV")
# 30538 obs
lm5<- lmer(log(Netopening) ~ LogDepthCenter:EstSweepCat
           + (1|Ship:EstSweepCat) + (1|Ship:Qfac:StatRec), 
           data=train, REML=FALSE)
summary(lm5)
r.squaredGLMM(lm5)

the_gov$mod1_net_gov<-exp(predict(lm5, the_gov, allow.new.levels=T))

summary(the_gov$mod1_net_gov)

###############################
# If real values are available use these
# predict results for spains net opening data
hauls$Use_Netopening[!is.na(hauls$Netopening)&
                       hauls$Gear=="GOV"]<-hauls$Netopening[!is.na(hauls$Netopening)&
                                                              hauls$Gear=="GOV"]
hauls$QualityNet[!is.na(hauls$Netopening)]<-"raw_netopening"

list<-the_gov$UniqueID
###########pick up after lunch

hauls$mod1_net_gov[hauls$UniqueID%in%list]<-the_gov$mod1_net_gov[the_gov$UniqueID%in%list]

hauls$Use_Netopening[is.na(hauls$Netopening)&
                       hauls$Gear=="GOV"]<-hauls$mod1_net_gov[is.na(hauls$Netopening)&
                                                                       hauls$Gear=="GOV"]
hauls$QualityNet[is.na(hauls$Netopening)&!is.na(hauls$mod1_net_gov)&
                    hauls$Gear=="GOV"]<-"mod1_net_gov"

#check door spreads
summary((hauls$Use_Netopening[hauls$Gear=="GOV"]))
summary(as.factor(hauls$QualityNet[hauls$Gear=="GOV"]))

summary((hauls$Use_Netopening))
summary(as.factor(hauls$QualityNet))

summary((hauls$Use_WingSpread))
summary(as.factor(hauls$QualityWing))

# remove some mods and other objects from R env
rm(data, devFunOnly.lmerTest.private, door_mod, l.lmerTest.private.contrast,
   ll, lm1, lm2,lm3, lm4, lm5, lm3a, lm7a, reml.lmerTest.private, the_gov,
   train)
##############################
# Calculate Swept Area- Wing #
##############################
summary((hauls$Use_WingSpread))
summary(hauls$newDist)
100*100

hauls$SweptArea_wing_m_sqrd<-hauls$Use_WingSpread*hauls$newDist
hauls$SweptArea_wing_km_sqrd<-hauls$SweptArea_wing_m_sqrd/1000
summary(hauls$SweptArea_wing_km_sqrd)
16.05/68.12
16.05/0.23
hauls[, c("QualityWing_SweptArea") := list(paste0(qualityDistance, hauls$QualityWing)),]  

hauls[, c("Wing/Door(Ratio)"):= list(hauls$Use_WingSpread/hauls$Use_DoorSpread),]
# Save "raw" files - before all estimated data is added
write.csv(HH, "Raw_Combined_Data_20-05-2016.csv")
write.csv(HH_baka, "Raw_baka_files_20-05-2016.csv")
write.csv(HH_beams, "Raw_beams_files_20-05-2016.csv")
write.csv(HH_gov, "Raw_gov_files_20-05-2016.csv")
write.csv(HH_nct, "Raw_nct_files_20-05-2016.csv")
write.csv(HH_rot, "Raw_rot_files_20-05-2016.csv")
write.csv(HH_rot1, "Raw_rot1_files_20-05-2016.csv")
# remove from R environment
rm(HH_baka, HH_beams, HH_gov, HH_nct, HH_rot, HH_rot1, HH)
# Save monster HH Chron File
write.csv(hauls, "final_full_cleaned_hauls_27-05-2016.csv")

# take a list of haul IDs for use in the HL observation selection 
list<-hauls$UniqueID

# get a master hauls file - for the front end product with the selected fields
# Select only valid hauls during the day?? and select important columns
#Select only GOV hauls
# hauls <- HH[HH$HaulVal=='V' & HH$Gear=='GOV']
# keepers <- c("Survey", "Country","StNo","Quarter", "StatRec", "Depth", "HaulDur", "Distance",
#              "GroundSpeed", "Ship", "Year", "WingSpread", "HaulLat",
#             "HaulLong", "ShootLat", "ShootLong", "DoorSpread", 
#             "Netopening","SweepLngt", "Gear")
# others <- colnames(hauls)[!colnames(hauls) %in% keepers]
# hauls[, c(others):= NULL]
